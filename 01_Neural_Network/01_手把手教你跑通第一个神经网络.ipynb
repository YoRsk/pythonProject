{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确保 `import torch` 不报错！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的环境 `torch.__version__: 1.8.0` + `python3.8.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch.__version__: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 实现 `__getitem__` 和 `__len__` 两个magic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpledataset.__getitem__(0): {'x': tensor(-1.), 'y': tensor(1.)}\n",
      "simpledataset[0]: {'x': tensor(-1.), 'y': tensor(1.)}\n",
      "simpledataset.__len__(): 10\n",
      "len(simpledataset): 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "\n",
    "def eg_1_1():\n",
    "  \"\"\"\n",
    "  Eg1.1 : __getitem__, __len__\n",
    "  \"\"\"\n",
    "  x = torch.linspace(-1, 1, 10)\n",
    "  y = x**2\n",
    "\n",
    "  class SimpleDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "      super().__init__()\n",
    "      self.x = x\n",
    "      self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      return {\"x\":self.x[index], \"y\":self.y[index]}\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.x)\n",
    "\n",
    "  simpledataset = SimpleDataset(x, y)\n",
    "  index = 0\n",
    "  # __getitem__\n",
    "  print(\"simpledataset.__getitem__({}): {}\".format(index, simpledataset.__getitem__(index)))\n",
    "  print(\"simpledataset[{}]: {}\".format(index, simpledataset[index]))\n",
    "  # __len__\n",
    "  print(\"simpledataset.__len__(): {}\".format(simpledataset.__len__()))\n",
    "  print(\"len(simpledataset): {}\".format(len(simpledataset)))\n",
    "\n",
    "eg_1_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 理解 `MNIST` 类，以及 `transforms` 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_dataset): <class 'torchvision.datasets.mnist.MNIST'>\n",
      "train_dataset[0]: (<PIL.Image.Image image mode=L size=28x28 at 0x7FF837B97640>, 5)\n",
      "len(train_dataset): 60000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eg_1_2_0():\n",
    "  \"\"\"\n",
    "  Eg1.2.0 : MNIST\n",
    "  \"\"\"\n",
    "  from torchvision.datasets.mnist import MNIST\n",
    "  train_dataset = MNIST(root=\"./mnist_data\",\n",
    "                        train=True,\n",
    "                        transform=None,\n",
    "                        download=False)\n",
    "\n",
    "  print(\"type(train_dataset): {}\".format(type(train_dataset)))  # <class 'torchvision.datasets.mnist.MNIST'>\n",
    "  index = 0\n",
    "  print(\"train_dataset[{}]: {}\".format(index, train_dataset[index]))  # (PIL.Image.Image, 5)\n",
    "  print(\"len(train_dataset): {}\".format(len(train_dataset)))\n",
    "\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "  plt.imshow(train_dataset[index][0], cmap ='gray')\n",
    "  plt.show()\n",
    "\n",
    "eg_1_2_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_dataset[0]): <class 'tuple'>\n",
      "type(train_dataset[0][0]): <class 'torch.Tensor'>\n",
      "train_dataset[0][0].shape: torch.Size([1, 28, 28])\n",
      "type(train_dataset[0][1]): <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "def eg_1_2_1():\n",
    "  \"\"\"\n",
    "  Eg1.2.1 : transforms\n",
    "  \"\"\"\n",
    "  from torchvision.datasets.mnist import MNIST\n",
    "  from torchvision import transforms\n",
    "\n",
    "  transform = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ]\n",
    "  )\n",
    "  train_dataset = MNIST(root=\"./mnist_data\",\n",
    "                        train=True,\n",
    "                        transform=transform,\n",
    "                        target_transform=None,\n",
    "                        download=False)\n",
    "\n",
    "  index = 0\n",
    "  print(\"type(train_dataset[{}]): {}\".format(index, type(train_dataset[index])))  # <class 'tuple'>\n",
    "  print(\"type(train_dataset[{}][0]): {}\".format(index, type(train_dataset[index][0])))  # <class 'torch.Tensor'>\n",
    "  print(\"train_dataset[{}][0].shape: {}\".format(index, train_dataset[index][0].shape))  # torch.Size([1, 28, 28])\n",
    "  print(\"type(train_dataset[{}][1]): {}\".format(index, type(train_dataset[index][1])))  # <class 'int'>\n",
    "\n",
    "\n",
    "eg_1_2_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 利用 `torchvision.datasets` 中的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(segmentation_dataset[0]): <class 'tuple'>\n",
      "type(segmentation_dataset[0][0]): <class 'PIL.Image.Image'>\n",
      "type(segmentation_dataset[0][1]): <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "type(detection_dataset[0]): <class 'tuple'>\n",
      "type(detection_dataset[0][0]): <class 'PIL.Image.Image'>\n",
      "type(detection_dataset[0][1]): <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "def eg_1_3():\n",
    "  \"\"\"\n",
    "  Eg1.3 : VOCSegmentation, VOCDetection\n",
    "  \"\"\"\n",
    "  from torchvision.datasets.voc import VOCSegmentation, VOCDetection\n",
    "\n",
    "  segmentation_dataset = VOCSegmentation(root=\"./voc_data\",\n",
    "                                        image_set=\"train\",\n",
    "                                        transform=None,\n",
    "                                        download=False)\n",
    "  detection_dataset = VOCDetection(root=\"./voc_data\",\n",
    "                                  image_set=\"train\",\n",
    "                                  transform=None,\n",
    "                                  download=False)\n",
    "\n",
    "  index = 0\n",
    "  print(\"type(segmentation_dataset[{}]): {}\".format(index, type(segmentation_dataset[index])))  # <class 'tuple'>\n",
    "  print(\"type(segmentation_dataset[{}][0]): {}\".format(index, type(segmentation_dataset[index][0])))  # <class 'PIL.Image.Image'>\n",
    "  print(\"type(segmentation_dataset[{}][1]): {}\".format(index, type(segmentation_dataset[index][1])))  # <class 'PIL.PngImagePlugin.PngImageFile'>\n",
    "\n",
    "  print(\"type(detection_dataset[{}]): {}\".format(index, type(detection_dataset[index])))  # <class 'tuple'>\n",
    "  print(\"type(detection_dataset[{}][0]): {}\".format(index, type(detection_dataset[index][0])))  # <class 'PIL.Image.Image'>\n",
    "  print(\"type(detection_dataset[{}][1]): {}\".format(index, type(detection_dataset[index][1])))  # <class 'dict'>\n",
    "\n",
    "eg_1_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 理解 `ImageFolder` 类及其 `classes` 与 `class_to_idx` 属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_dataset[0]): <class 'tuple'>\n",
      "type(train_dataset[0][0]): <class 'torch.Tensor'>\n",
      "train_dataset[0][0].shape: torch.Size([3, 224, 224])\n",
      "type(train_dataset[0][1]): <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "def eg_1_4_0():\n",
    "  \"\"\"\n",
    "  Eg1.4.0 : ImageFolder\n",
    "  \"\"\"\n",
    "  from torchvision.datasets import ImageFolder\n",
    "  from torchvision import transforms\n",
    "\n",
    "  transform = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomResizedCrop(size=(224, 224)),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "  )\n",
    "  train_dataset = ImageFolder(root=os.path.join(\"./flower_data\", \"train\"), transform=transform)\n",
    "\n",
    "  index = 0\n",
    "  print(\"type(train_dataset[{}]): {}\".format(index, type(train_dataset[index])))  # <class 'tuple'>\n",
    "  print(\"type(train_dataset[{}][0]): {}\".format(index, type(train_dataset[index][0])))  # <class 'torch.Tensor'>\n",
    "  print(\"train_dataset[{}][0].shape: {}\".format(index, train_dataset[index][0].shape))  # torch.Size([3, 224, 224])\n",
    "  print(\"type(train_dataset[{}][1]): {}\".format(index, type(train_dataset[index][1])))  # <class 'int'>\n",
    "\n",
    "eg_1_4_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset.classes: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
      "train_dataset.class_to_idx: {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n"
     ]
    }
   ],
   "source": [
    "def eg_1_4_1():\n",
    "  \"\"\"\n",
    "  Eg1.4.1 : classes, class_to_idx\n",
    "  \"\"\"\n",
    "  from torchvision.datasets import ImageFolder\n",
    "  from torchvision import transforms\n",
    "\n",
    "  transform = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomResizedCrop(size=(224, 224)),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "  )\n",
    "  train_dataset = ImageFolder(root=os.path.join(\"./flower_data\", \"train\"), transform=transform)\n",
    "\n",
    "  print(\"train_dataset.classes: {}\".format(train_dataset.classes))  # ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "  print(\"train_dataset.class_to_idx: {}\".format(train_dataset.class_to_idx))  # {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n",
    "\n",
    "eg_1_4_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 利用 `torch.utils.data.DataLoader`类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data._utils import collate\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "transform = transforms.Compose(\n",
    "  [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "  ]\n",
    ")\n",
    "\n",
    "train_dataset = MNIST(root=\"./mnist_data\",\n",
    "                      train=True,\n",
    "                      transform=transform,\n",
    "                      target_transform=None,\n",
    "                      download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 理解 `__iter__` 这个magic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_loader): <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "type(batch): <class 'list'>\n",
      "len(batch): 2\n",
      "type(batch[0]): <class 'torch.Tensor'>\n",
      "type(batch[1]): <class 'torch.Tensor'>\n",
      "batch[0].shape: torch.Size([10000, 1, 28, 28])\n",
      "batch[1].shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def eg_2_1():\n",
    "  \"\"\"\n",
    "  Eg2.1 : __iter__\n",
    "  \"\"\"\n",
    "  from torch.utils.data import DataLoader\n",
    "  train_loader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=10000,\n",
    "                            shuffle=False)\n",
    "\n",
    "  print(\"type(train_loader): {}\".format(type(train_loader)))  # <class 'torch.utils.data.dataloader.DataLoader'>\n",
    "  for batch in train_loader:\n",
    "    print(\"type(batch): {}\".format(type(batch)))  # <class 'list'>\n",
    "    print(\"len(batch): {}\".format(len(batch)))  # 2\n",
    "    print(\"type(batch[0]): {}\".format(type(batch[0])))  # <class 'torch.Tensor'>\n",
    "    print(\"type(batch[1]): {}\".format(type(batch[0])))  # <class 'torch.Tensor'>\n",
    "    print(\"batch[0].shape: {}\".format(batch[0].shape))  # torch.Size([10000, 1, 28, 28])\n",
    "    print(\"batch[1].shape: {}\".format(batch[1].shape))  # torch.Size([10000])\n",
    "    break\n",
    "\n",
    "eg_2_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 区分 `Dataloader` 与 `Dataset` 的 `__len__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader): 6\n",
      "len(train_loader.dataset): 60000\n"
     ]
    }
   ],
   "source": [
    "def eg_2_2():\n",
    "  \"\"\"\n",
    "  Eg2.2 : __len__\n",
    "  \"\"\"\n",
    "  from torch.utils.data import DataLoader\n",
    "  train_loader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=10000,\n",
    "                            shuffle=False)\n",
    "\n",
    "  print(\"len(train_loader): {}\".format(len(train_loader)))  # 6\n",
    "  print(\"len(train_loader.dataset): {}\".format(len(train_loader.dataset)))  # 60000\n",
    "\n",
    "eg_2_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 利用 内置函数 `enumerate` 与 `tqdm` 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0, type(x): <class 'torch.Tensor'>, type(y): <class 'torch.Tensor'>\n",
      "batch: 0, x.shape: torch.Size([10000, 1, 28, 28]), y.shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def eg_2_3_0():\n",
    "  \"\"\"\n",
    "  Eg2.3.0 : enumerate\n",
    "  \"\"\"\n",
    "  from torch.utils.data import DataLoader\n",
    "  train_loader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=10000,\n",
    "                            shuffle=False)\n",
    "\n",
    "  for batch, (x, y) in enumerate(train_loader):\n",
    "    print(\"batch: {}, type(x): {}, type(y): {}\".format(batch, type(x), type(y)))\n",
    "    # batch: 0, type(x): <class 'torch.Tensor'>, type(y): <class 'torch.Tensor'>\n",
    "    print(\"batch: {}, x.shape: {}, y.shape: {}\".format(batch, x.shape, y.shape))\n",
    "    # batch: 0, x.shape: torch.Size([10000, 1, 28, 28]), y.shape: torch.Size([10000])\n",
    "    break\n",
    "\n",
    "eg_2_3_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: 100%|██████████| 6/6 [00:11<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "def eg_2_3_1():\n",
    "  \"\"\"\n",
    "  Eg2.3.1 : tqdm\n",
    "  \"\"\"\n",
    "  from torch.utils.data import DataLoader\n",
    "  from tqdm import tqdm\n",
    "  train_loader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=10000,\n",
    "                            shuffle=False)\n",
    "\n",
    "  with tqdm(train_loader, desc=\"TRAINING\") as train_bar:\n",
    "    for (x, y) in train_bar:\n",
    "      pass\n",
    "\n",
    "eg_2_3_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 有需要可以更改 `collate_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(batch): <class 'list'>, len(batch): 10000\n",
      "type(batch): <class 'dict'>\n",
      "type(batch[\"x\"]): <class 'torch.Tensor'>\n",
      "type(batch[\"y\"]): <class 'torch.Tensor'>\n",
      "batch[\"x\"].shape: torch.Size([10000, 1, 28, 28])\n",
      "batch[\"y\"].shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "def eg_2_4():\n",
    "  \"\"\"\n",
    "  Eg2.4 : collate_fn\n",
    "  \"\"\"\n",
    "  def collate_fn(batch):\n",
    "    print(\"type(batch): {}, len(batch): {}\".format(type(batch), len(batch)))  # <class 'list'>, 10000\n",
    "    x = [i[0] for i in batch]\n",
    "    y = [i[1] for i in batch]\n",
    "    x = torch.cat(x)[:,None,...]\n",
    "    y = torch.Tensor(y)\n",
    "    return {\"x\":x, \"y\":y}\n",
    "\n",
    "  from torch.utils.data import DataLoader\n",
    "  from tqdm import tqdm\n",
    "  train_loader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=10000,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=collate_fn)\n",
    "\n",
    "  for batch in train_loader:\n",
    "    print(\"type(batch): {}\".format(type(batch)))  # <class 'dict'>\n",
    "    print(\"type(batch[\\\"x\\\"]): {}\".format(type(batch[\"x\"])))  # <class 'torch.Tensor'>\n",
    "    print(\"type(batch[\\\"y\\\"]): {}\".format(type(batch[\"y\"])))  # <class 'torch.Tensor'>\n",
    "    print(\"batch[\\\"x\\\"].shape: {}\".format(batch[\"x\"].shape))  # torch.Size([10000, 1, 28, 28])\n",
    "    print(\"batch[\\\"y\\\"].shape: {}\".format(batch[\"y\"].shape))  # torch.Size([10000])\n",
    "    break\n",
    "\n",
    "eg_2_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 继承 `torch.nn.Module`，注意 `super().__init__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "transform = transforms.Compose(\n",
    "  [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "  ]\n",
    ")\n",
    "\n",
    "train_dataset = MNIST(root=\"./mnist_data\",\n",
    "                      train=True,\n",
    "                      transform=transform,\n",
    "                      target_transform=None,\n",
    "                      download=False)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=10000,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: SimpleModel(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "conv1.weight Parameter containing:\n",
      "tensor([[[[-0.6109]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3560]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7688]]]], requires_grad=True)\n",
      "conv1.bias Parameter containing:\n",
      "tensor([0.3276, 0.4379, 0.1914], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "def eg_3_0_0():\n",
    "  \"\"\"\n",
    "  Eg3.0.0 : torch.nn.Module\n",
    "  \"\"\"\n",
    "  from torch import nn\n",
    "  class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=(1, 1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "  model = SimpleModel()\n",
    "  print(\"model: {}\".format(model))\n",
    "  for name, param in model.named_parameters():\n",
    "    print(name, param)\n",
    "\n",
    "eg_3_0_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: SimpleModel(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def eg_3_0_1():\n",
    "  \"\"\"\n",
    "  Eg3.0.1 : super().__init__()\n",
    "  \"\"\"\n",
    "  from torch import nn\n",
    "  class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # super(SimpleModel, self).__init__()  # 这一行注释了就会报错\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=(1, 1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "  model = SimpleModel()\n",
    "  print(\"model: {}\".format(model))\n",
    "\n",
    "eg_3_0_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 理解 `__call__` 这个magic method 与自定义 `forward` 关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]],\n",
      "\n",
      "         [[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]]]])\n"
     ]
    }
   ],
   "source": [
    "def eg_3_1():\n",
    "  \"\"\"\n",
    "  Eg3.1 : __call__  [magic methods]\n",
    "  \"\"\"\n",
    "  from torch import nn\n",
    "  class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=(1, 1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "  model = SimpleModel()\n",
    "  x = train_dataset[0][0]  # torch.Size([1, 28, 28])\n",
    "  x = x[None, ...]  # torch.Size([1, 1, 28, 28])\n",
    "  print(model(x) == model.forward(x))\n",
    "\n",
    "eg_3_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 注意 `PyTorch` 中数据的摆放 `(B, C, H ,W)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[before flatten] x.shape: torch.Size([1, 5, 28, 28])\n",
      "[after flatten] x.shape: torch.Size([1, 3920])\n"
     ]
    }
   ],
   "source": [
    "def eg_3_2():\n",
    "  \"\"\"\n",
    "  Eg3.2 : (B, C, H ,W)\n",
    "  \"\"\"\n",
    "  from torch import nn\n",
    "  class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(1, 1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        self.linear = nn.Linear(in_features=5*28*28, out_features=10, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        print(\"[before flatten] x.shape: {}\".format(x.shape))  # torch.Size([1, 5, 28, 28])\n",
    "        x = self.flatten(x)\n",
    "        print(\"[after flatten] x.shape: {}\".format(x.shape))  # torch.Size([1, 3920])\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "  model = SimpleModel()\n",
    "  x = train_dataset[0][0]  # torch.Size([1, 28, 28])\n",
    "  x = x[None, ...]  # torch.Size([1, 1, 28, 28])\n",
    "  model(x)\n",
    "\n",
    "eg_3_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 调用 `torchvison.models` 中现成的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_vgg16: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "model_resnet50: ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def eg_3_3():\n",
    "  \"\"\"\n",
    "  Eg3.3 : torchvision.models\n",
    "  \"\"\"\n",
    "  from torchvision import models\n",
    "\n",
    "  model_vgg16 = models.vgg16()\n",
    "  print(\"model_vgg16: {}\".format(model_vgg16))\n",
    "\n",
    "  model_resnet50 = models.resnet50()\n",
    "  print(\"model_resnet50: {}\".format(model_resnet50))\n",
    "\n",
    "eg_3_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 注意 `torch.nn.Module.dict_state()` `torch.save()` `torch.load()` 以及 `torch.nn.Module.load_state_dict()` 及其中参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_vgg16.state_dict(): OrderedDict([('features.0.weight', tensor([[[[-0.0058, -0.0429,  0.0137],\n",
      "          [-0.0189,  0.0206,  0.1407],\n",
      "          [-0.0653,  0.0660, -0.0481]],\n",
      "\n",
      "         [[-0.0466,  0.0410,  0.0329],\n",
      "          [ 0.0776,  0.0679, -0.0501],\n",
      "          [ 0.0294, -0.0630,  0.0480]],\n",
      "\n",
      "         [[ 0.0011,  0.0027,  0.0596],\n",
      "          [-0.0246,  0.0191,  0.0520],\n",
      "          [-0.0086, -0.0190,  0.0418]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0062, -0.0272,  0.0264],\n",
      "          [ 0.0057, -0.0713, -0.0427],\n",
      "          [-0.0140, -0.0929, -0.0218]],\n",
      "\n",
      "         [[ 0.0050,  0.0358,  0.1720],\n",
      "          [ 0.0286, -0.0034,  0.0096],\n",
      "          [-0.0026, -0.0059,  0.1130]],\n",
      "\n",
      "         [[-0.1007, -0.0538,  0.0306],\n",
      "          [-0.0770, -0.0982, -0.0755],\n",
      "          [-0.0319, -0.0327,  0.0189]]],\n",
      "\n",
      "\n",
      "        [[[-0.1196, -0.0211,  0.0087],\n",
      "          [-0.0336, -0.0478, -0.1100],\n",
      "          [ 0.0894,  0.0243,  0.0103]],\n",
      "\n",
      "         [[ 0.0776,  0.0885, -0.0192],\n",
      "          [ 0.0592,  0.0244,  0.0605],\n",
      "          [-0.0230, -0.0351, -0.1095]],\n",
      "\n",
      "         [[ 0.0032, -0.0173, -0.0318],\n",
      "          [ 0.0171,  0.1167,  0.0647],\n",
      "          [ 0.0763,  0.0455, -0.0668]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0720, -0.0316, -0.0387],\n",
      "          [ 0.0633, -0.0093, -0.0125],\n",
      "          [ 0.0289,  0.0909,  0.0148]],\n",
      "\n",
      "         [[ 0.0046,  0.0179, -0.0522],\n",
      "          [ 0.0997, -0.0234,  0.0398],\n",
      "          [-0.0272, -0.0016,  0.0817]],\n",
      "\n",
      "         [[-0.0665, -0.1130,  0.1082],\n",
      "          [ 0.1044,  0.0397, -0.0058],\n",
      "          [-0.0478,  0.1348,  0.0747]]],\n",
      "\n",
      "\n",
      "        [[[-0.0733, -0.1851,  0.0318],\n",
      "          [-0.1138,  0.0740, -0.0374],\n",
      "          [ 0.0716,  0.1062, -0.0451]],\n",
      "\n",
      "         [[ 0.0849, -0.0070, -0.0269],\n",
      "          [ 0.0577,  0.1075,  0.1082],\n",
      "          [ 0.0072, -0.0111,  0.0839]],\n",
      "\n",
      "         [[-0.0396, -0.0018,  0.0489],\n",
      "          [ 0.0084, -0.0689,  0.0476],\n",
      "          [ 0.0357,  0.1882, -0.0092]]],\n",
      "\n",
      "\n",
      "        [[[-0.0859, -0.0120, -0.0678],\n",
      "          [ 0.0339, -0.0270, -0.0450],\n",
      "          [ 0.0156,  0.0725,  0.0281]],\n",
      "\n",
      "         [[ 0.0981,  0.0731,  0.0129],\n",
      "          [ 0.0324,  0.0689,  0.0429],\n",
      "          [-0.0592,  0.0655,  0.1102]],\n",
      "\n",
      "         [[-0.0312, -0.0004,  0.0006],\n",
      "          [-0.0115, -0.0425, -0.0801],\n",
      "          [-0.0376, -0.0284, -0.0141]]]])), ('features.0.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('features.2.weight', tensor([[[[ 8.4797e-02,  2.8971e-02, -4.2445e-02],\n",
      "          [ 3.6968e-03, -3.5056e-02, -2.3158e-02],\n",
      "          [-8.0122e-02, -9.4988e-02, -5.4971e-02]],\n",
      "\n",
      "         [[ 1.4578e-02,  1.3769e-01,  4.1991e-02],\n",
      "          [-9.4635e-02,  4.8270e-02, -4.3999e-02],\n",
      "          [ 3.2624e-03,  1.2303e-01,  4.9448e-03]],\n",
      "\n",
      "         [[ 7.8258e-02, -6.8937e-02, -3.5214e-02],\n",
      "          [ 1.1342e-02, -5.2887e-02, -1.9984e-02],\n",
      "          [ 2.6641e-02,  6.1373e-02, -6.2112e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6008e-02, -1.4316e-02, -8.6017e-02],\n",
      "          [ 9.2413e-02,  1.5329e-03, -1.1819e-02],\n",
      "          [-7.0963e-02, -1.3503e-03, -2.1069e-03]],\n",
      "\n",
      "         [[ 4.7248e-02, -2.3619e-02,  6.1764e-02],\n",
      "          [-2.7669e-02, -5.1224e-02,  1.1275e-02],\n",
      "          [-2.0796e-02,  1.2217e-03, -6.2143e-02]],\n",
      "\n",
      "         [[-5.5395e-03,  9.0270e-02,  1.9917e-02],\n",
      "          [-5.9155e-02, -5.2784e-02,  6.7214e-02],\n",
      "          [-6.8221e-02, -1.6529e-01, -3.2909e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4800e-02, -8.0121e-02, -1.2675e-02],\n",
      "          [-6.5118e-02,  6.7265e-02, -9.0730e-02],\n",
      "          [ 7.8983e-02,  3.9565e-02,  1.3089e-01]],\n",
      "\n",
      "         [[ 5.4955e-02,  3.5341e-02,  4.6366e-02],\n",
      "          [ 2.7913e-02, -4.4526e-02,  1.1365e-01],\n",
      "          [ 3.2010e-02,  2.1520e-02, -2.9198e-03]],\n",
      "\n",
      "         [[ 5.4353e-02,  8.9082e-02,  8.9715e-03],\n",
      "          [ 9.1044e-03,  5.7604e-02,  2.2158e-02],\n",
      "          [ 1.0345e-01, -2.5009e-02, -6.7942e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.7426e-02,  9.2599e-03,  6.8386e-02],\n",
      "          [ 6.0771e-02, -4.3732e-03,  1.1483e-02],\n",
      "          [ 4.1002e-03,  8.9970e-02,  2.0537e-02]],\n",
      "\n",
      "         [[-4.6307e-02, -2.9111e-02, -4.2317e-02],\n",
      "          [-5.4095e-03,  3.3033e-02, -7.0233e-02],\n",
      "          [-2.1544e-02, -4.1733e-02,  8.3644e-02]],\n",
      "\n",
      "         [[-2.1626e-02, -4.4798e-02,  4.8739e-02],\n",
      "          [-3.9584e-02, -2.5416e-02, -4.5298e-02],\n",
      "          [-1.0902e-01, -1.9108e-02, -4.1865e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0403e-02, -8.7034e-02, -7.5968e-02],\n",
      "          [-2.4019e-02,  2.2392e-02, -7.3035e-03],\n",
      "          [-3.2373e-04, -1.0101e-01, -5.8432e-02]],\n",
      "\n",
      "         [[ 3.6826e-02, -2.5207e-02,  9.2228e-03],\n",
      "          [ 2.2508e-02,  5.6193e-02,  2.2061e-02],\n",
      "          [ 4.4507e-02, -1.8878e-02,  3.5220e-02]],\n",
      "\n",
      "         [[ 9.5948e-02,  7.3020e-02, -7.7774e-04],\n",
      "          [ 5.3343e-03, -2.1242e-02, -4.4850e-02],\n",
      "          [ 1.7074e-02, -7.9259e-02, -7.1655e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1196e-02,  2.1120e-02,  1.1530e-01],\n",
      "          [ 3.0199e-02, -2.5899e-03, -3.1567e-02],\n",
      "          [ 6.6479e-03,  1.3650e-02, -1.8059e-02]],\n",
      "\n",
      "         [[-3.3876e-02,  6.4873e-02, -6.6663e-02],\n",
      "          [ 4.3115e-02, -4.8905e-02,  4.3405e-02],\n",
      "          [-3.5761e-02,  3.5264e-02, -4.6147e-02]],\n",
      "\n",
      "         [[-3.1363e-02, -1.2756e-02, -3.9218e-02],\n",
      "          [-2.9347e-02,  2.9507e-02, -2.4010e-02],\n",
      "          [ 3.2064e-02,  2.9464e-02, -1.2343e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.6096e-03,  6.5317e-02,  5.2787e-02],\n",
      "          [-2.8571e-02, -5.8849e-02,  8.0178e-02],\n",
      "          [ 4.9149e-03, -3.5749e-02,  9.3951e-03]],\n",
      "\n",
      "         [[-1.2013e-01, -7.5116e-03,  7.4593e-02],\n",
      "          [ 5.0396e-02,  4.2715e-02, -1.1748e-02],\n",
      "          [ 4.5287e-02,  5.8500e-03, -1.3812e-01]],\n",
      "\n",
      "         [[ 8.2308e-02, -1.4029e-02, -9.5843e-03],\n",
      "          [-5.7437e-04, -6.8761e-02,  6.5826e-02],\n",
      "          [ 5.9781e-02, -2.2618e-02,  3.0288e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.2083e-02, -9.0287e-02,  1.8323e-02],\n",
      "          [ 2.6573e-02, -1.2315e-01, -2.0037e-02],\n",
      "          [-3.7915e-03, -6.8166e-03,  7.1848e-02]],\n",
      "\n",
      "         [[ 9.6802e-02, -1.1498e-02, -6.8760e-02],\n",
      "          [-5.9423e-02, -3.7652e-02,  7.2002e-02],\n",
      "          [-3.4556e-05,  5.0035e-02, -6.5224e-02]],\n",
      "\n",
      "         [[-8.0316e-02, -9.9455e-03,  2.0094e-02],\n",
      "          [-9.8593e-02, -2.1017e-03, -6.9550e-02],\n",
      "          [-2.8378e-02,  6.8656e-02,  3.0612e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.1607e-02, -1.1480e-01, -4.3435e-02],\n",
      "          [ 1.8550e-02,  1.8030e-02,  6.0376e-02],\n",
      "          [ 3.6738e-02, -5.0909e-02,  4.0208e-02]],\n",
      "\n",
      "         [[ 3.2145e-02, -3.6429e-03, -7.7804e-02],\n",
      "          [ 5.4205e-03, -6.0056e-02, -1.3281e-01],\n",
      "          [-3.7674e-02,  2.7231e-02,  2.7783e-02]],\n",
      "\n",
      "         [[ 7.5123e-02,  5.2831e-02, -2.6043e-02],\n",
      "          [-8.1399e-03, -6.2251e-02,  4.5994e-02],\n",
      "          [ 6.3275e-02, -1.7219e-02, -7.2811e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.1590e-02, -3.9716e-02, -8.9942e-02],\n",
      "          [-1.3112e-03, -3.4848e-02, -7.1796e-02],\n",
      "          [ 3.4562e-02, -1.9008e-02, -2.8794e-02]],\n",
      "\n",
      "         [[-1.4581e-02,  5.6519e-03, -2.7933e-02],\n",
      "          [ 1.0518e-02, -1.6093e-01, -3.6386e-02],\n",
      "          [-4.3268e-02,  2.2478e-02,  1.0262e-02]],\n",
      "\n",
      "         [[ 3.5004e-02,  3.7667e-02,  5.3874e-02],\n",
      "          [-9.1674e-03,  1.9764e-02, -2.8501e-02],\n",
      "          [-7.2572e-02,  4.8684e-02,  2.6788e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1574e-03,  3.6132e-02, -6.5985e-02],\n",
      "          [ 3.4277e-02, -8.5457e-02, -1.3203e-01],\n",
      "          [-1.2226e-02,  3.3047e-02, -2.3952e-02]],\n",
      "\n",
      "         [[ 1.5002e-01,  1.4479e-02, -3.5135e-02],\n",
      "          [-1.1939e-01, -2.4352e-02,  6.0766e-02],\n",
      "          [ 2.0641e-02,  3.7369e-02, -1.3175e-01]],\n",
      "\n",
      "         [[ 9.5272e-02,  9.7388e-03, -5.9880e-02],\n",
      "          [-1.7354e-02, -6.0511e-03,  3.8842e-02],\n",
      "          [-5.3795e-02, -1.1104e-01,  2.8688e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4504e-02,  2.4141e-02,  6.7656e-02],\n",
      "          [-3.4801e-02,  5.3496e-02, -1.1584e-01],\n",
      "          [-3.7281e-02, -1.9649e-02, -1.3844e-01]],\n",
      "\n",
      "         [[ 9.6664e-03,  2.9376e-02, -8.6372e-02],\n",
      "          [ 3.0057e-02,  8.6891e-02,  1.1963e-02],\n",
      "          [ 3.2688e-02,  2.2282e-02, -3.8400e-02]],\n",
      "\n",
      "         [[ 5.5859e-02,  8.7283e-02,  2.3035e-02],\n",
      "          [-5.0977e-02,  2.5675e-03, -7.1959e-02],\n",
      "          [ 5.9377e-02, -1.2214e-02, -4.4369e-02]]]])), ('features.2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('features.5.weight', tensor([[[[-0.0029, -0.0014, -0.0308],\n",
      "          [-0.0232, -0.0360, -0.0293],\n",
      "          [ 0.0162, -0.0139,  0.0085]],\n",
      "\n",
      "         [[ 0.0912,  0.0142, -0.0535],\n",
      "          [ 0.0096,  0.0176, -0.0372],\n",
      "          [ 0.0087, -0.0794,  0.0235]],\n",
      "\n",
      "         [[ 0.0289, -0.0384, -0.0229],\n",
      "          [-0.1000, -0.0459,  0.0201],\n",
      "          [-0.0714, -0.0613,  0.0197]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0002, -0.0343, -0.0744],\n",
      "          [-0.0043, -0.0349,  0.0557],\n",
      "          [-0.0339,  0.0223, -0.0462]],\n",
      "\n",
      "         [[ 0.0178,  0.0215,  0.0041],\n",
      "          [ 0.0106,  0.0307, -0.0767],\n",
      "          [ 0.0604, -0.0411,  0.0507]],\n",
      "\n",
      "         [[ 0.0212, -0.0122,  0.0538],\n",
      "          [ 0.0072, -0.0267, -0.0350],\n",
      "          [ 0.0517, -0.0036, -0.0516]]],\n",
      "\n",
      "\n",
      "        [[[-0.0197,  0.0100, -0.0067],\n",
      "          [ 0.0701,  0.0611,  0.0866],\n",
      "          [ 0.0595,  0.0340, -0.0244]],\n",
      "\n",
      "         [[ 0.0394, -0.0020, -0.0333],\n",
      "          [ 0.0786,  0.0216,  0.0428],\n",
      "          [-0.0823,  0.0546, -0.0116]],\n",
      "\n",
      "         [[ 0.0515,  0.0389, -0.0634],\n",
      "          [ 0.0134, -0.0093,  0.0361],\n",
      "          [ 0.1121,  0.0018,  0.0461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0030,  0.0421, -0.0280],\n",
      "          [-0.0073,  0.0310,  0.0089],\n",
      "          [ 0.0404,  0.0736, -0.0496]],\n",
      "\n",
      "         [[ 0.0218,  0.0115, -0.0243],\n",
      "          [ 0.0046, -0.0298, -0.0698],\n",
      "          [-0.0538,  0.0334,  0.0180]],\n",
      "\n",
      "         [[-0.0431,  0.0337, -0.0278],\n",
      "          [ 0.0213,  0.0382, -0.0189],\n",
      "          [ 0.0232,  0.0075, -0.0188]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0717,  0.0196, -0.0523],\n",
      "          [-0.0182,  0.0305,  0.0357],\n",
      "          [ 0.0990,  0.0991, -0.0561]],\n",
      "\n",
      "         [[-0.0006, -0.0440, -0.0381],\n",
      "          [-0.0286, -0.0024,  0.0686],\n",
      "          [ 0.0110,  0.0355, -0.0397]],\n",
      "\n",
      "         [[-0.0587,  0.0402, -0.0361],\n",
      "          [ 0.0347, -0.0476, -0.0351],\n",
      "          [-0.0744,  0.0690, -0.0590]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0587,  0.0095,  0.0723],\n",
      "          [ 0.0475, -0.0072,  0.0931],\n",
      "          [-0.0466, -0.0170,  0.0447]],\n",
      "\n",
      "         [[ 0.0159, -0.0115,  0.0187],\n",
      "          [-0.0667,  0.0051, -0.0761],\n",
      "          [-0.0191,  0.0186,  0.0897]],\n",
      "\n",
      "         [[ 0.0400, -0.0056, -0.0415],\n",
      "          [-0.0318,  0.0235,  0.0813],\n",
      "          [-0.0561,  0.0240, -0.0124]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0407,  0.0236, -0.0226],\n",
      "          [ 0.0200, -0.0014,  0.0226],\n",
      "          [-0.0342,  0.0052,  0.0176]],\n",
      "\n",
      "         [[-0.0594, -0.0097, -0.0244],\n",
      "          [ 0.0249,  0.0523,  0.0775],\n",
      "          [ 0.0430,  0.0197, -0.0051]],\n",
      "\n",
      "         [[ 0.0106, -0.0148,  0.0026],\n",
      "          [-0.0357,  0.0001, -0.1054],\n",
      "          [ 0.0414, -0.0192, -0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0421, -0.0577, -0.0339],\n",
      "          [ 0.0513, -0.0412,  0.0541],\n",
      "          [-0.0529, -0.0006, -0.0029]],\n",
      "\n",
      "         [[ 0.0420, -0.0125, -0.0481],\n",
      "          [ 0.0280,  0.0414, -0.0316],\n",
      "          [ 0.0265, -0.0331, -0.0913]],\n",
      "\n",
      "         [[-0.0201,  0.0250,  0.0237],\n",
      "          [-0.0481, -0.0022, -0.0285],\n",
      "          [ 0.0716, -0.0570, -0.0386]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0215,  0.1031,  0.0319],\n",
      "          [ 0.0060,  0.0012,  0.0447],\n",
      "          [-0.0242,  0.0180,  0.0293]],\n",
      "\n",
      "         [[-0.0227, -0.0222, -0.0434],\n",
      "          [-0.0378,  0.0658,  0.0025],\n",
      "          [-0.0026,  0.0402, -0.0678]],\n",
      "\n",
      "         [[ 0.0019,  0.0224, -0.0389],\n",
      "          [-0.0243,  0.0220,  0.0709],\n",
      "          [-0.0342,  0.0076,  0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0410, -0.0006,  0.0026],\n",
      "          [-0.0251, -0.0232,  0.0584],\n",
      "          [-0.0949, -0.0443, -0.0612]],\n",
      "\n",
      "         [[ 0.0785, -0.0225, -0.0029],\n",
      "          [ 0.0168, -0.0173,  0.0545],\n",
      "          [-0.0113,  0.0879, -0.0625]],\n",
      "\n",
      "         [[ 0.0196,  0.0724, -0.0410],\n",
      "          [-0.0149,  0.0175,  0.0248],\n",
      "          [ 0.0644, -0.0795,  0.0332]]],\n",
      "\n",
      "\n",
      "        [[[-0.0564, -0.0144, -0.0644],\n",
      "          [ 0.0041,  0.0207, -0.0162],\n",
      "          [ 0.0361, -0.1177,  0.0010]],\n",
      "\n",
      "         [[ 0.0002, -0.0155,  0.0079],\n",
      "          [ 0.0347,  0.0016, -0.0377],\n",
      "          [ 0.0215, -0.0779, -0.0414]],\n",
      "\n",
      "         [[ 0.0213,  0.0018,  0.0097],\n",
      "          [-0.0158,  0.0236,  0.0391],\n",
      "          [ 0.0027, -0.0044, -0.0640]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0951, -0.0306, -0.0369],\n",
      "          [-0.0931, -0.0206,  0.0223],\n",
      "          [-0.0428, -0.0052,  0.0048]],\n",
      "\n",
      "         [[-0.0176,  0.0841,  0.0361],\n",
      "          [ 0.0310,  0.0168,  0.0016],\n",
      "          [ 0.0064,  0.0478,  0.0015]],\n",
      "\n",
      "         [[ 0.0081, -0.0341, -0.0182],\n",
      "          [-0.0086, -0.0008, -0.0028],\n",
      "          [ 0.0119, -0.0202, -0.0384]]]])), ('features.5.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('features.7.weight', tensor([[[[ 1.6501e-02,  1.0378e-01,  8.9367e-03],\n",
      "          [ 1.6399e-02, -1.9415e-02,  2.2027e-02],\n",
      "          [ 5.4267e-02, -2.8150e-02, -2.6679e-03]],\n",
      "\n",
      "         [[ 4.5888e-02,  2.1552e-02,  1.1759e-02],\n",
      "          [ 2.1807e-02,  4.6896e-02,  5.6470e-02],\n",
      "          [-3.3072e-02,  1.7963e-02,  1.0435e-02]],\n",
      "\n",
      "         [[-1.8164e-02, -3.8526e-02, -7.6670e-02],\n",
      "          [-1.0780e-02, -7.3000e-02, -1.5388e-04],\n",
      "          [-1.3709e-02,  6.0633e-02,  1.1000e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.7984e-02, -2.6653e-03, -4.7430e-02],\n",
      "          [-1.1168e-01,  3.1873e-02, -2.1865e-02],\n",
      "          [-2.0273e-03,  6.0454e-02, -1.4240e-02]],\n",
      "\n",
      "         [[ 2.5951e-02,  4.2385e-03, -7.8019e-03],\n",
      "          [-8.5244e-02,  4.0450e-02,  3.8535e-02],\n",
      "          [-6.8183e-03, -2.5962e-02, -3.4512e-03]],\n",
      "\n",
      "         [[-1.3681e-02, -7.1166e-03, -2.7988e-02],\n",
      "          [-2.2790e-02,  5.2191e-02, -3.1569e-02],\n",
      "          [-2.8774e-02,  1.1043e-02, -8.5053e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2007e-02,  6.1991e-02,  4.7685e-02],\n",
      "          [ 7.9123e-04, -3.1703e-02,  4.2009e-02],\n",
      "          [ 3.4852e-02,  2.4266e-02, -5.8073e-02]],\n",
      "\n",
      "         [[ 3.5957e-02, -5.7801e-02,  2.1571e-02],\n",
      "          [ 3.8188e-02,  9.2553e-03, -8.1309e-05],\n",
      "          [-5.0362e-02, -3.3008e-02, -3.5104e-03]],\n",
      "\n",
      "         [[ 2.6691e-02, -2.5830e-02,  6.4328e-02],\n",
      "          [-8.2559e-04,  2.5616e-02, -6.6914e-02],\n",
      "          [-2.9020e-02, -5.7278e-02, -1.6361e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5372e-02,  1.4441e-02,  3.9997e-02],\n",
      "          [-1.8190e-02, -3.3759e-02,  5.3796e-02],\n",
      "          [-2.0821e-02,  4.7421e-02,  4.3101e-02]],\n",
      "\n",
      "         [[ 2.0568e-02, -4.8399e-02,  1.7584e-02],\n",
      "          [-3.1404e-02,  3.9553e-02, -1.6184e-02],\n",
      "          [-4.5007e-02,  4.3781e-02, -1.8262e-04]],\n",
      "\n",
      "         [[ 2.5786e-02,  8.2789e-03,  1.4926e-03],\n",
      "          [-3.3275e-02, -4.2372e-02,  1.0443e-02],\n",
      "          [ 5.4074e-02,  6.0261e-03,  3.5858e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4032e-02, -1.5276e-02,  9.5789e-02],\n",
      "          [ 1.2047e-02, -1.8587e-02,  1.1287e-04],\n",
      "          [-6.7268e-02, -1.0312e-01,  3.6629e-02]],\n",
      "\n",
      "         [[ 1.4008e-02,  1.9150e-02,  5.8700e-02],\n",
      "          [-8.1500e-02, -2.3769e-03, -6.6526e-02],\n",
      "          [ 4.1229e-02,  7.2496e-02, -4.0134e-02]],\n",
      "\n",
      "         [[ 5.0155e-02, -2.1411e-02, -7.2541e-02],\n",
      "          [ 1.2146e-02,  1.5299e-02,  8.3484e-02],\n",
      "          [-9.9785e-02, -6.8519e-02, -6.1630e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2576e-02,  1.1641e-02, -4.4518e-02],\n",
      "          [ 1.4766e-02, -2.5786e-02,  7.9232e-02],\n",
      "          [-2.3472e-02,  4.4444e-02, -4.7550e-02]],\n",
      "\n",
      "         [[ 3.5436e-02, -4.0958e-02,  2.4936e-02],\n",
      "          [-1.6222e-02,  7.5066e-02, -1.0550e-01],\n",
      "          [-3.6237e-02, -5.1774e-02,  1.6763e-03]],\n",
      "\n",
      "         [[-4.2939e-02,  1.9396e-02, -1.4527e-02],\n",
      "          [ 1.2674e-02, -3.4098e-02,  1.0925e-02],\n",
      "          [-9.1966e-04,  3.6910e-02,  6.9696e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.0682e-02,  7.3224e-02, -2.4671e-02],\n",
      "          [-2.6790e-02, -4.7585e-03,  9.0610e-02],\n",
      "          [-2.2944e-02, -1.0345e-01,  6.3827e-02]],\n",
      "\n",
      "         [[-7.2391e-03, -3.0109e-02,  9.9681e-03],\n",
      "          [-1.0785e-02,  3.4157e-03,  7.7312e-02],\n",
      "          [ 5.1009e-02,  2.2542e-02, -2.0479e-02]],\n",
      "\n",
      "         [[-3.6194e-02, -3.0239e-02, -3.6729e-02],\n",
      "          [ 6.1556e-03, -1.7710e-02, -4.7740e-02],\n",
      "          [ 2.4981e-02, -8.3620e-02, -1.4947e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6845e-02, -1.0070e-02,  8.6513e-02],\n",
      "          [-1.3591e-03, -4.7372e-03,  1.6019e-02],\n",
      "          [-1.5788e-02,  2.1091e-02,  2.5630e-02]],\n",
      "\n",
      "         [[ 1.5109e-02, -3.4237e-02,  4.0454e-02],\n",
      "          [ 1.3895e-02,  6.0834e-02,  6.8734e-02],\n",
      "          [ 2.0274e-02, -2.3780e-02, -6.3197e-03]],\n",
      "\n",
      "         [[ 3.9001e-03, -3.6194e-02, -3.2106e-02],\n",
      "          [-1.5207e-02, -5.6638e-02,  2.6152e-02],\n",
      "          [ 5.5258e-02, -3.4312e-02,  1.0389e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1810e-02,  1.1419e-01,  1.4098e-02],\n",
      "          [ 4.7049e-02,  5.2147e-02,  2.3723e-02],\n",
      "          [ 1.0572e-02, -6.9217e-03, -2.0027e-02]],\n",
      "\n",
      "         [[-7.0163e-02, -5.9606e-02,  5.0043e-03],\n",
      "          [ 2.3094e-02,  7.3076e-03,  2.9700e-02],\n",
      "          [ 1.5212e-02,  1.3467e-02, -1.6010e-02]],\n",
      "\n",
      "         [[-5.1667e-02, -1.0641e-02, -2.5301e-02],\n",
      "          [ 8.0438e-03,  1.6526e-02, -2.7252e-02],\n",
      "          [ 7.1105e-02,  6.7926e-04, -6.2796e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.9677e-02,  3.6779e-02, -4.3647e-02],\n",
      "          [ 7.0757e-02,  7.2539e-02, -1.9451e-02],\n",
      "          [-6.6427e-02,  5.2805e-02,  4.7433e-02]],\n",
      "\n",
      "         [[ 1.3786e-02, -3.2706e-02, -2.6781e-02],\n",
      "          [-5.7175e-02,  1.8031e-02,  2.4288e-02],\n",
      "          [ 6.8386e-03,  3.7457e-02,  2.7234e-02]],\n",
      "\n",
      "         [[-4.0257e-02, -5.0513e-02, -2.1028e-03],\n",
      "          [ 8.9102e-03,  2.8015e-02, -7.2539e-02],\n",
      "          [ 1.2797e-02,  5.8934e-03,  5.8229e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6509e-03, -8.8202e-03, -3.3182e-02],\n",
      "          [-2.9320e-02, -2.8306e-02, -2.7669e-02],\n",
      "          [ 2.6412e-02,  1.9350e-02, -8.7551e-02]],\n",
      "\n",
      "         [[ 1.2626e-02,  3.9181e-02,  6.9844e-02],\n",
      "          [ 7.5143e-02, -1.2007e-02, -5.2504e-02],\n",
      "          [-1.4397e-02,  6.2623e-03,  1.3975e-02]],\n",
      "\n",
      "         [[ 1.6767e-02,  3.2615e-02,  9.7265e-02],\n",
      "          [-1.9832e-02,  9.1304e-04,  1.8536e-02],\n",
      "          [-4.9566e-03, -4.8595e-02, -2.6662e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2798e-02,  7.1266e-02, -1.0997e-03],\n",
      "          [-9.7396e-03, -7.3191e-03, -1.4830e-02],\n",
      "          [ 1.5836e-02, -5.6168e-02,  1.3068e-02]],\n",
      "\n",
      "         [[ 1.4069e-02,  4.6308e-02,  5.2846e-02],\n",
      "          [-6.7891e-03, -3.9499e-03, -1.1924e-02],\n",
      "          [ 4.6026e-02, -3.8070e-03, -1.9746e-02]],\n",
      "\n",
      "         [[ 3.1951e-02,  3.5922e-02, -9.8934e-02],\n",
      "          [-6.8868e-02, -5.7159e-02, -3.5663e-02],\n",
      "          [ 6.0952e-03, -6.0121e-03,  3.1136e-02]]]])), ('features.7.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('features.10.weight', tensor([[[[-0.0297,  0.0471, -0.0015],\n",
      "          [ 0.0415, -0.0011, -0.0204],\n",
      "          [-0.0430, -0.0357,  0.0225]],\n",
      "\n",
      "         [[-0.0337,  0.0689, -0.0313],\n",
      "          [ 0.0241, -0.0721, -0.0204],\n",
      "          [ 0.0017,  0.0084,  0.0105]],\n",
      "\n",
      "         [[-0.0096, -0.0079,  0.0153],\n",
      "          [-0.0282, -0.0283,  0.0119],\n",
      "          [ 0.0051, -0.0341,  0.0129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0095, -0.0054, -0.0116],\n",
      "          [ 0.1052,  0.0374, -0.0181],\n",
      "          [ 0.0168, -0.0564, -0.0422]],\n",
      "\n",
      "         [[ 0.0264,  0.0009, -0.0263],\n",
      "          [ 0.0173, -0.0539,  0.0096],\n",
      "          [-0.0153, -0.0081, -0.0069]],\n",
      "\n",
      "         [[-0.0074, -0.0208, -0.0162],\n",
      "          [ 0.0015, -0.0041,  0.0014],\n",
      "          [ 0.0265, -0.0139,  0.0226]]],\n",
      "\n",
      "\n",
      "        [[[-0.0458,  0.0004, -0.0074],\n",
      "          [ 0.0467, -0.0269, -0.0294],\n",
      "          [ 0.0017,  0.0160, -0.0368]],\n",
      "\n",
      "         [[ 0.0507,  0.0132, -0.0435],\n",
      "          [-0.0348, -0.0221,  0.0230],\n",
      "          [ 0.0024,  0.0245, -0.0030]],\n",
      "\n",
      "         [[ 0.0176,  0.0126, -0.0249],\n",
      "          [-0.0218,  0.0175,  0.0020],\n",
      "          [ 0.0109, -0.0504,  0.0175]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0262,  0.0265,  0.0448],\n",
      "          [ 0.0310,  0.0331,  0.0090],\n",
      "          [-0.0096, -0.0008, -0.0221]],\n",
      "\n",
      "         [[ 0.0060,  0.0287,  0.0199],\n",
      "          [ 0.0194, -0.0229,  0.0088],\n",
      "          [ 0.0081,  0.0279, -0.0360]],\n",
      "\n",
      "         [[ 0.0235,  0.0438,  0.0252],\n",
      "          [ 0.0222, -0.0209,  0.0162],\n",
      "          [ 0.0389,  0.0122, -0.0027]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0247, -0.0353,  0.0083],\n",
      "          [-0.0366,  0.0449,  0.0082],\n",
      "          [ 0.0131,  0.0233,  0.0200]],\n",
      "\n",
      "         [[ 0.0433,  0.0423, -0.0518],\n",
      "          [-0.0758,  0.0217, -0.0028],\n",
      "          [ 0.0080,  0.0197, -0.0268]],\n",
      "\n",
      "         [[ 0.0069, -0.0068,  0.0054],\n",
      "          [ 0.0132, -0.0074,  0.0299],\n",
      "          [ 0.0671, -0.0238, -0.0065]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0120,  0.0414,  0.0070],\n",
      "          [ 0.0440,  0.0158,  0.0266],\n",
      "          [ 0.0077, -0.0415, -0.0448]],\n",
      "\n",
      "         [[ 0.0166, -0.0160,  0.0035],\n",
      "          [ 0.0106,  0.0033,  0.0483],\n",
      "          [-0.0141, -0.0456,  0.0039]],\n",
      "\n",
      "         [[-0.0225, -0.0089, -0.0080],\n",
      "          [-0.0037,  0.0257, -0.0117],\n",
      "          [-0.0635,  0.0010,  0.0193]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0105,  0.0214, -0.0090],\n",
      "          [-0.0842,  0.0235,  0.0504],\n",
      "          [ 0.0416,  0.0225, -0.0110]],\n",
      "\n",
      "         [[-0.0261,  0.0059, -0.0135],\n",
      "          [-0.0367,  0.0084,  0.0003],\n",
      "          [-0.0157, -0.0281,  0.0294]],\n",
      "\n",
      "         [[ 0.0321, -0.0113, -0.0001],\n",
      "          [-0.0233, -0.0311, -0.0107],\n",
      "          [ 0.0302,  0.0529, -0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0183, -0.0318, -0.0530],\n",
      "          [ 0.0197,  0.0195,  0.0063],\n",
      "          [-0.0455, -0.0250,  0.0083]],\n",
      "\n",
      "         [[ 0.0151, -0.0298, -0.0429],\n",
      "          [-0.0663, -0.0040, -0.0494],\n",
      "          [ 0.0042,  0.0455, -0.0569]],\n",
      "\n",
      "         [[-0.0106, -0.0256,  0.0828],\n",
      "          [ 0.0075,  0.0199, -0.0146],\n",
      "          [-0.0605, -0.0028, -0.0371]]],\n",
      "\n",
      "\n",
      "        [[[-0.0160, -0.0299, -0.0261],\n",
      "          [-0.0105, -0.0031,  0.0035],\n",
      "          [ 0.0016, -0.0699, -0.0063]],\n",
      "\n",
      "         [[ 0.0239,  0.0006, -0.0290],\n",
      "          [ 0.0463,  0.0188, -0.0535],\n",
      "          [ 0.0027, -0.0644,  0.0177]],\n",
      "\n",
      "         [[-0.0358, -0.0275,  0.0143],\n",
      "          [ 0.0134,  0.0075,  0.0168],\n",
      "          [ 0.0046, -0.0120, -0.0303]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0385,  0.0094,  0.0011],\n",
      "          [-0.0270, -0.0032, -0.0439],\n",
      "          [-0.0031,  0.0270,  0.0052]],\n",
      "\n",
      "         [[ 0.0440,  0.0225, -0.0100],\n",
      "          [-0.0131, -0.0211,  0.0052],\n",
      "          [-0.0213,  0.0086,  0.0098]],\n",
      "\n",
      "         [[-0.0359,  0.0410, -0.0161],\n",
      "          [-0.0474, -0.0373,  0.0002],\n",
      "          [ 0.0212, -0.0227,  0.0148]]],\n",
      "\n",
      "\n",
      "        [[[-0.0116,  0.0035, -0.0252],\n",
      "          [-0.0040, -0.0132,  0.0055],\n",
      "          [ 0.0378,  0.0561,  0.0144]],\n",
      "\n",
      "         [[ 0.0234, -0.0298,  0.0067],\n",
      "          [-0.0034, -0.0516, -0.0191],\n",
      "          [ 0.0005, -0.0320, -0.0278]],\n",
      "\n",
      "         [[ 0.0087,  0.0195,  0.0161],\n",
      "          [ 0.0396,  0.0162, -0.0070],\n",
      "          [ 0.0082,  0.0019, -0.0037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0598, -0.0402, -0.0368],\n",
      "          [ 0.0280,  0.0455, -0.0214],\n",
      "          [ 0.0779,  0.0338, -0.0363]],\n",
      "\n",
      "         [[-0.0216, -0.0437,  0.0266],\n",
      "          [ 0.0379, -0.0348,  0.0246],\n",
      "          [ 0.0022, -0.0165,  0.0350]],\n",
      "\n",
      "         [[ 0.0346,  0.0257, -0.0381],\n",
      "          [ 0.0603, -0.0448,  0.0010],\n",
      "          [-0.0123,  0.0123,  0.0444]]]])), ('features.10.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('features.12.weight', tensor([[[[-0.0487, -0.0085,  0.0612],\n",
      "          [-0.0376, -0.0006, -0.0213],\n",
      "          [-0.0043, -0.0263, -0.0053]],\n",
      "\n",
      "         [[ 0.0023,  0.0178, -0.0267],\n",
      "          [ 0.0246,  0.0129,  0.0353],\n",
      "          [-0.0366, -0.0296, -0.0044]],\n",
      "\n",
      "         [[-0.0249,  0.0529,  0.0166],\n",
      "          [-0.0202,  0.0058,  0.0338],\n",
      "          [ 0.0123,  0.0236,  0.0606]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0008,  0.0095,  0.0381],\n",
      "          [-0.0122, -0.0182, -0.0189],\n",
      "          [ 0.0250, -0.0254,  0.0140]],\n",
      "\n",
      "         [[ 0.0011,  0.0003, -0.0214],\n",
      "          [ 0.0075, -0.0347, -0.0265],\n",
      "          [ 0.0189,  0.0042, -0.0492]],\n",
      "\n",
      "         [[ 0.0077, -0.0239,  0.0432],\n",
      "          [-0.0032,  0.0427, -0.0106],\n",
      "          [ 0.0183, -0.0654,  0.0191]]],\n",
      "\n",
      "\n",
      "        [[[-0.0006,  0.0260, -0.0027],\n",
      "          [ 0.0346,  0.0011,  0.0346],\n",
      "          [ 0.0054, -0.0043,  0.0387]],\n",
      "\n",
      "         [[-0.0107, -0.0177,  0.0325],\n",
      "          [ 0.0009,  0.0155, -0.0223],\n",
      "          [ 0.0029,  0.0232, -0.0427]],\n",
      "\n",
      "         [[-0.0070,  0.0682, -0.0198],\n",
      "          [ 0.0292, -0.0280, -0.0251],\n",
      "          [ 0.0101,  0.0260, -0.0138]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0193,  0.0133, -0.0040],\n",
      "          [ 0.0316,  0.0422, -0.0630],\n",
      "          [-0.0357,  0.0336, -0.0050]],\n",
      "\n",
      "         [[ 0.0109,  0.0279, -0.0398],\n",
      "          [-0.0144,  0.0199, -0.0012],\n",
      "          [-0.0040, -0.0427, -0.0020]],\n",
      "\n",
      "         [[-0.0103, -0.0008,  0.0089],\n",
      "          [-0.0118,  0.0222,  0.0108],\n",
      "          [ 0.0074, -0.0060, -0.0078]]],\n",
      "\n",
      "\n",
      "        [[[-0.0266, -0.0219,  0.0742],\n",
      "          [-0.0138, -0.0043,  0.0249],\n",
      "          [-0.0197, -0.0546, -0.0530]],\n",
      "\n",
      "         [[-0.0070,  0.0028, -0.0566],\n",
      "          [ 0.0109,  0.0125,  0.0086],\n",
      "          [-0.0353, -0.0537, -0.0295]],\n",
      "\n",
      "         [[-0.0152, -0.0196, -0.0257],\n",
      "          [ 0.0449,  0.0235,  0.0286],\n",
      "          [ 0.0477,  0.0157,  0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0089,  0.0390,  0.0243],\n",
      "          [-0.0075, -0.0218, -0.0264],\n",
      "          [-0.0093,  0.0162, -0.0017]],\n",
      "\n",
      "         [[ 0.0325, -0.0017, -0.0074],\n",
      "          [-0.0046, -0.0143,  0.0224],\n",
      "          [-0.0187,  0.0060,  0.0071]],\n",
      "\n",
      "         [[-0.0072, -0.0014, -0.0328],\n",
      "          [-0.0228,  0.0055, -0.0018],\n",
      "          [ 0.0075, -0.0144,  0.0374]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0096, -0.0808, -0.0102],\n",
      "          [-0.0088,  0.0372,  0.0157],\n",
      "          [-0.0021, -0.0010, -0.0196]],\n",
      "\n",
      "         [[-0.0061,  0.0010,  0.0368],\n",
      "          [ 0.0138, -0.0680, -0.0508],\n",
      "          [-0.0667,  0.0011,  0.0091]],\n",
      "\n",
      "         [[ 0.0094,  0.0049, -0.0119],\n",
      "          [ 0.0008,  0.0347,  0.0391],\n",
      "          [-0.0083,  0.0161,  0.0136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0378,  0.0009,  0.0732],\n",
      "          [-0.0176, -0.0316, -0.0001],\n",
      "          [-0.0055, -0.0285, -0.0028]],\n",
      "\n",
      "         [[ 0.0132, -0.0143, -0.0235],\n",
      "          [ 0.0654,  0.0146, -0.0160],\n",
      "          [ 0.0048, -0.0137,  0.0322]],\n",
      "\n",
      "         [[ 0.0037,  0.0160,  0.0066],\n",
      "          [-0.0281, -0.0313,  0.0375],\n",
      "          [ 0.0058, -0.0130, -0.0029]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0177, -0.0112, -0.0570],\n",
      "          [-0.0198,  0.0343,  0.0261],\n",
      "          [-0.0424,  0.0018, -0.0060]],\n",
      "\n",
      "         [[-0.0433,  0.0155, -0.0057],\n",
      "          [ 0.0156,  0.0036, -0.0317],\n",
      "          [-0.0569, -0.0480,  0.0048]],\n",
      "\n",
      "         [[-0.0090, -0.0218, -0.0233],\n",
      "          [ 0.0255, -0.0165, -0.0466],\n",
      "          [-0.0268, -0.0034,  0.0090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0039, -0.0202, -0.0192],\n",
      "          [ 0.0135,  0.0091,  0.0339],\n",
      "          [ 0.0052,  0.0120,  0.0115]],\n",
      "\n",
      "         [[-0.0449,  0.0375, -0.0544],\n",
      "          [ 0.0042,  0.0044, -0.0019],\n",
      "          [ 0.0162,  0.0151,  0.0579]],\n",
      "\n",
      "         [[-0.0003, -0.0205, -0.0004],\n",
      "          [ 0.0326, -0.0044, -0.0237],\n",
      "          [ 0.0232, -0.0213, -0.0031]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0418,  0.0949, -0.0128],\n",
      "          [-0.0266,  0.0067, -0.0077],\n",
      "          [-0.0064, -0.0137,  0.0061]],\n",
      "\n",
      "         [[ 0.0316, -0.0192,  0.0308],\n",
      "          [-0.0144, -0.0027,  0.0214],\n",
      "          [-0.0173,  0.0065,  0.0448]],\n",
      "\n",
      "         [[ 0.0339, -0.0065, -0.0033],\n",
      "          [-0.0200,  0.0105,  0.0173],\n",
      "          [ 0.0347,  0.0215,  0.0241]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0119, -0.0433, -0.0201],\n",
      "          [-0.0053, -0.0096, -0.0327],\n",
      "          [-0.0153, -0.0432,  0.0327]],\n",
      "\n",
      "         [[ 0.0282,  0.0226, -0.0278],\n",
      "          [ 0.0026, -0.0354,  0.0098],\n",
      "          [ 0.0083, -0.0172,  0.0644]],\n",
      "\n",
      "         [[-0.0108, -0.0138, -0.0052],\n",
      "          [-0.0063,  0.0128, -0.0323],\n",
      "          [-0.0542,  0.0292, -0.0043]]]])), ('features.12.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('features.14.weight', tensor([[[[-1.8905e-02,  4.7951e-02, -5.9256e-03],\n",
      "          [-4.9279e-03, -1.0121e-02, -1.2693e-02],\n",
      "          [-1.9263e-03,  1.1681e-02,  2.7548e-02]],\n",
      "\n",
      "         [[ 1.9021e-02,  1.1109e-02,  8.4907e-04],\n",
      "          [ 3.2220e-02,  3.4402e-02,  3.6780e-03],\n",
      "          [-6.2312e-04,  4.5971e-03, -8.1376e-03]],\n",
      "\n",
      "         [[ 5.7614e-02, -4.0676e-02, -1.4267e-02],\n",
      "          [ 8.5037e-03,  2.8689e-03,  2.2644e-02],\n",
      "          [-2.6688e-02, -2.1218e-03,  3.2260e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2814e-02, -1.5844e-02,  4.4226e-03],\n",
      "          [-2.9731e-02,  2.2596e-02,  4.5153e-03],\n",
      "          [-6.8694e-02, -2.5545e-02, -1.3544e-04]],\n",
      "\n",
      "         [[ 3.6968e-02, -5.7705e-03, -5.7946e-02],\n",
      "          [-2.5901e-02,  1.8582e-02, -7.3952e-03],\n",
      "          [ 3.1773e-04,  6.5093e-02, -1.9809e-02]],\n",
      "\n",
      "         [[-1.4950e-02, -2.4824e-03,  2.5443e-02],\n",
      "          [ 8.5899e-03,  9.8378e-03, -9.6364e-03],\n",
      "          [ 2.2169e-02, -6.6588e-03,  5.6489e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1860e-02, -2.7149e-03,  3.6731e-03],\n",
      "          [-7.8035e-03, -9.5097e-03, -6.7860e-02],\n",
      "          [ 3.8371e-02,  6.4870e-03, -1.7537e-03]],\n",
      "\n",
      "         [[ 4.9351e-03,  1.7831e-02,  4.3551e-02],\n",
      "          [ 1.1696e-02, -2.0703e-02, -4.3055e-02],\n",
      "          [ 1.8140e-02,  3.9924e-02,  1.3187e-02]],\n",
      "\n",
      "         [[ 4.6085e-02, -9.2465e-03, -9.9523e-03],\n",
      "          [ 2.3355e-02,  1.9439e-02, -6.1736e-02],\n",
      "          [ 1.3799e-02, -5.8381e-03,  5.9262e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6792e-02, -1.7533e-02,  3.4787e-02],\n",
      "          [-1.9293e-02, -6.5327e-02,  6.8084e-03],\n",
      "          [ 8.0339e-03, -2.8802e-02, -1.8569e-03]],\n",
      "\n",
      "         [[-1.6403e-02,  1.6056e-02, -9.2139e-03],\n",
      "          [ 6.3721e-02, -7.8219e-03, -4.9037e-02],\n",
      "          [ 5.5994e-03,  4.0809e-02, -3.1391e-02]],\n",
      "\n",
      "         [[-2.9814e-02, -2.3161e-02, -1.0955e-02],\n",
      "          [-2.4525e-02,  2.5661e-02,  4.4539e-02],\n",
      "          [ 4.9945e-03,  2.6028e-02,  1.9386e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1634e-02, -4.2903e-03, -4.2986e-02],\n",
      "          [ 5.6910e-02, -5.1090e-02, -4.7595e-03],\n",
      "          [ 1.2975e-02, -2.8365e-02,  8.4972e-03]],\n",
      "\n",
      "         [[ 3.3031e-02,  4.7321e-02, -1.6843e-02],\n",
      "          [ 3.7167e-02,  1.8758e-02,  2.3908e-02],\n",
      "          [-4.6862e-03,  1.3742e-02,  2.7480e-02]],\n",
      "\n",
      "         [[ 1.1431e-02,  2.3789e-02, -1.9687e-02],\n",
      "          [ 1.8256e-02,  2.5989e-02, -6.5714e-03],\n",
      "          [ 3.4420e-02,  1.1813e-02,  1.7318e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8787e-02,  4.1937e-02, -4.5560e-04],\n",
      "          [-3.4615e-02, -2.9644e-02,  6.3797e-02],\n",
      "          [-4.3288e-02, -3.8939e-02, -4.3781e-02]],\n",
      "\n",
      "         [[-4.7952e-02,  2.8760e-02,  1.1230e-03],\n",
      "          [ 3.2180e-02, -1.5430e-02, -5.0261e-02],\n",
      "          [ 1.3211e-02, -3.6830e-03, -1.0297e-02]],\n",
      "\n",
      "         [[ 2.8592e-03, -5.5839e-02,  6.3517e-04],\n",
      "          [-3.9500e-02,  1.2725e-02, -3.4035e-02],\n",
      "          [ 2.6453e-02, -9.7516e-03,  4.5713e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7498e-02,  2.8881e-02, -2.6797e-02],\n",
      "          [ 3.2817e-02,  1.7581e-02,  3.8376e-03],\n",
      "          [ 1.1384e-02, -1.2536e-02, -3.7965e-02]],\n",
      "\n",
      "         [[-1.6562e-02,  3.7870e-02,  7.8580e-03],\n",
      "          [-7.3321e-03, -2.5192e-02, -4.0139e-02],\n",
      "          [-8.5199e-03, -7.3117e-05,  3.9342e-02]],\n",
      "\n",
      "         [[-4.5476e-02,  2.8176e-02, -1.9589e-02],\n",
      "          [-2.6867e-02,  1.5534e-02,  1.6755e-02],\n",
      "          [ 1.3545e-03,  3.3917e-02, -4.3265e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.4092e-03,  1.0826e-02, -5.8868e-02],\n",
      "          [-2.3362e-03,  1.3827e-02, -2.0339e-02],\n",
      "          [-1.7023e-02,  2.7895e-02,  1.1939e-02]],\n",
      "\n",
      "         [[ 3.0005e-02,  1.9215e-02, -7.6825e-02],\n",
      "          [-3.6907e-02,  3.6554e-02,  3.2598e-02],\n",
      "          [ 1.0690e-02,  1.9001e-02,  7.2939e-03]],\n",
      "\n",
      "         [[-1.2168e-02,  5.9378e-02,  2.0096e-02],\n",
      "          [ 9.3954e-04,  4.8637e-03,  1.5681e-02],\n",
      "          [-2.1155e-02, -3.1243e-02, -5.4531e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2034e-02,  2.2083e-02,  8.4725e-03],\n",
      "          [ 7.9542e-03, -4.5646e-02,  4.4445e-03],\n",
      "          [ 3.9444e-02, -4.8159e-02, -5.0454e-02]],\n",
      "\n",
      "         [[-2.2254e-02, -6.0567e-03,  1.5396e-02],\n",
      "          [ 3.4244e-02,  2.2490e-02, -1.0069e-03],\n",
      "          [ 1.2218e-02,  3.7644e-02, -2.2574e-02]],\n",
      "\n",
      "         [[-7.0113e-02, -1.5091e-02,  9.4634e-03],\n",
      "          [ 7.3851e-03,  4.0033e-02,  5.7201e-03],\n",
      "          [-1.2774e-02, -1.9540e-04,  2.1566e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1934e-02, -1.5675e-02,  7.9319e-03],\n",
      "          [ 3.1298e-02,  4.8693e-02, -3.4145e-02],\n",
      "          [ 3.3032e-03,  5.6892e-03,  2.8895e-02]],\n",
      "\n",
      "         [[-3.4726e-02,  5.0539e-02,  2.7997e-02],\n",
      "          [ 4.2760e-02, -1.2912e-02,  4.6157e-02],\n",
      "          [ 2.8956e-03,  3.6083e-02,  8.0212e-03]],\n",
      "\n",
      "         [[ 5.3110e-03,  2.2642e-02, -3.0505e-02],\n",
      "          [ 1.0862e-02, -1.7523e-02, -1.7506e-02],\n",
      "          [-1.2165e-02, -5.8667e-02,  3.5321e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3506e-02, -1.9071e-03,  3.7307e-03],\n",
      "          [-3.6492e-02,  4.0602e-02,  7.4822e-02],\n",
      "          [ 1.2425e-02,  1.5595e-02, -6.1345e-02]],\n",
      "\n",
      "         [[-1.7238e-02,  2.2839e-02, -4.3144e-02],\n",
      "          [-1.8985e-02, -2.1541e-02,  3.1021e-03],\n",
      "          [ 7.1597e-03, -9.1546e-04, -1.2228e-02]],\n",
      "\n",
      "         [[ 5.0241e-02, -9.8962e-03,  2.8768e-03],\n",
      "          [-1.0629e-02,  7.6026e-02, -2.5636e-02],\n",
      "          [ 3.3283e-02,  2.0593e-02, -2.1422e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0807e-03,  6.4193e-02, -3.2177e-02],\n",
      "          [-1.5444e-02,  3.3283e-02, -1.2394e-02],\n",
      "          [-2.2946e-04,  2.1308e-02, -2.5120e-02]],\n",
      "\n",
      "         [[ 5.6895e-02,  2.6233e-02,  1.5276e-02],\n",
      "          [-1.7534e-02,  2.9851e-03, -2.0824e-02],\n",
      "          [ 4.1627e-02, -2.7531e-04,  1.1054e-02]],\n",
      "\n",
      "         [[ 5.1693e-03, -3.5625e-02,  9.8889e-03],\n",
      "          [ 2.6093e-02, -1.0304e-02,  4.6907e-03],\n",
      "          [ 2.1263e-02,  8.3768e-03, -3.0365e-02]]]])), ('features.14.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('features.17.weight', tensor([[[[ 1.2679e-02, -1.8388e-02,  1.0828e-02],\n",
      "          [ 8.4870e-03, -1.3784e-02, -2.9590e-03],\n",
      "          [-3.8458e-02, -1.5666e-02, -1.9581e-02]],\n",
      "\n",
      "         [[-2.5951e-02, -6.3973e-02,  4.6193e-02],\n",
      "          [-3.0161e-03,  4.5523e-03, -2.4834e-02],\n",
      "          [-1.6209e-02, -1.0580e-02, -1.2533e-02]],\n",
      "\n",
      "         [[ 4.1337e-02,  1.8201e-04, -1.3593e-02],\n",
      "          [ 9.2874e-03,  1.1326e-02,  2.6692e-03],\n",
      "          [ 1.1298e-03, -2.5370e-04, -2.3583e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.1849e-03, -1.6214e-02, -2.3315e-02],\n",
      "          [ 3.0544e-03,  9.6189e-03,  4.0318e-03],\n",
      "          [ 3.2316e-02,  1.9915e-02, -1.4350e-02]],\n",
      "\n",
      "         [[ 9.0660e-03,  2.1458e-02, -2.0900e-02],\n",
      "          [-3.5973e-02, -1.2452e-02,  2.0537e-02],\n",
      "          [-4.3425e-03,  9.2299e-03,  2.0557e-03]],\n",
      "\n",
      "         [[ 1.8840e-02,  3.0326e-03, -9.5430e-03],\n",
      "          [-1.6705e-03,  1.3049e-02, -1.6494e-02],\n",
      "          [-8.2483e-03, -5.9907e-03, -4.8581e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5143e-04, -5.0717e-03, -9.0269e-03],\n",
      "          [ 3.1059e-02,  2.5002e-02,  2.7854e-02],\n",
      "          [-7.3372e-03,  4.5101e-02, -6.8395e-03]],\n",
      "\n",
      "         [[-1.8434e-02,  2.1498e-02, -1.5749e-02],\n",
      "          [-1.6882e-03, -1.9380e-03, -3.7340e-02],\n",
      "          [-1.6465e-02, -1.0793e-02, -1.2197e-02]],\n",
      "\n",
      "         [[-1.7554e-02, -1.0657e-02,  1.0330e-02],\n",
      "          [-3.7711e-02, -8.8342e-03, -4.3821e-02],\n",
      "          [-2.1669e-02, -1.0322e-02,  6.7104e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2389e-03, -1.9203e-02, -1.8389e-02],\n",
      "          [-2.0089e-02, -2.3471e-02, -8.0331e-03],\n",
      "          [ 2.8603e-02, -7.4936e-03, -2.3379e-02]],\n",
      "\n",
      "         [[ 6.0621e-04,  2.4512e-02, -3.0839e-02],\n",
      "          [-2.6096e-02,  3.5075e-02,  1.0888e-02],\n",
      "          [ 2.4236e-02, -2.3929e-03, -2.6149e-02]],\n",
      "\n",
      "         [[ 9.6045e-03,  1.7005e-02,  2.5794e-02],\n",
      "          [ 3.3346e-02,  4.3666e-02, -9.8584e-03],\n",
      "          [-1.9569e-02,  3.1562e-02, -6.3773e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8934e-04,  1.3200e-02,  2.1915e-02],\n",
      "          [-3.2408e-05, -4.4664e-03, -1.7125e-02],\n",
      "          [-8.1567e-03,  1.4683e-02, -2.2453e-02]],\n",
      "\n",
      "         [[ 4.3492e-03, -3.8470e-02, -8.3835e-03],\n",
      "          [ 1.5549e-02, -1.8317e-02, -2.2513e-02],\n",
      "          [-2.2624e-02, -2.3647e-02,  6.2665e-03]],\n",
      "\n",
      "         [[-3.6834e-02,  7.8556e-03,  3.8337e-03],\n",
      "          [-1.5317e-02,  5.2687e-03, -2.8403e-02],\n",
      "          [ 4.1019e-02, -1.8265e-03,  3.0696e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7372e-02, -2.3195e-02, -3.6314e-02],\n",
      "          [-3.8160e-03,  8.3967e-03,  7.4484e-03],\n",
      "          [ 7.4891e-03, -1.5952e-02,  1.6208e-02]],\n",
      "\n",
      "         [[-1.8938e-02, -1.7215e-02,  3.1026e-03],\n",
      "          [ 2.8260e-02,  1.3350e-02, -2.3747e-03],\n",
      "          [ 3.2778e-02, -1.9980e-02, -1.7903e-02]],\n",
      "\n",
      "         [[-6.0901e-03, -9.4139e-03,  1.7843e-02],\n",
      "          [-2.9921e-03,  1.4008e-02, -3.0487e-02],\n",
      "          [-3.9325e-02,  1.9095e-02, -1.2105e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.2977e-03,  1.2732e-02, -4.5006e-03],\n",
      "          [-1.4452e-02, -8.3336e-03,  4.1299e-02],\n",
      "          [-1.4995e-02,  3.9340e-02, -2.1640e-02]],\n",
      "\n",
      "         [[-1.1876e-02, -1.2341e-02, -2.5863e-02],\n",
      "          [ 3.5768e-02, -1.5885e-02, -2.0903e-02],\n",
      "          [-2.5903e-02, -1.0950e-03,  3.8163e-03]],\n",
      "\n",
      "         [[-1.7407e-02,  2.1347e-02, -3.8038e-03],\n",
      "          [-1.0889e-02,  5.8342e-03,  2.9161e-02],\n",
      "          [-2.8307e-02, -4.3904e-02, -3.3995e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7372e-02,  3.7014e-03, -2.4797e-02],\n",
      "          [-2.2302e-02,  2.3825e-02, -8.2529e-03],\n",
      "          [ 1.5101e-02, -1.3634e-02, -6.5303e-03]],\n",
      "\n",
      "         [[-2.6211e-02,  4.5676e-03,  1.5506e-02],\n",
      "          [-5.7283e-03,  1.1380e-02, -1.4154e-02],\n",
      "          [-1.3204e-02,  2.5766e-03, -7.1174e-03]],\n",
      "\n",
      "         [[ 1.7746e-02,  8.5374e-03, -2.8894e-02],\n",
      "          [-2.6746e-03, -1.5999e-02, -1.7283e-03],\n",
      "          [-1.9270e-03, -5.1342e-03, -1.7360e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4200e-02, -5.2498e-03, -9.7551e-03],\n",
      "          [ 1.5038e-02, -3.7479e-02, -3.3112e-02],\n",
      "          [ 2.5556e-03, -1.3806e-02,  3.5470e-02]],\n",
      "\n",
      "         [[-2.0233e-04,  2.9358e-02,  3.4747e-02],\n",
      "          [ 1.9121e-02, -1.6417e-02,  1.1285e-03],\n",
      "          [ 1.4031e-02,  3.4719e-02, -5.6685e-03]],\n",
      "\n",
      "         [[-4.8182e-03, -1.0469e-03,  6.0667e-03],\n",
      "          [ 1.4011e-02,  7.0741e-03, -4.5867e-02],\n",
      "          [ 2.3245e-02, -6.9671e-03,  1.0770e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0514e-02, -1.2878e-02, -2.5052e-02],\n",
      "          [-5.3139e-03,  1.9816e-02, -2.1671e-02],\n",
      "          [-5.4537e-03,  1.2244e-02,  5.8666e-03]],\n",
      "\n",
      "         [[ 6.4751e-03,  1.5380e-02,  2.9709e-02],\n",
      "          [-6.8313e-04,  1.4710e-05, -2.6962e-02],\n",
      "          [ 3.0019e-02, -3.9009e-03, -2.5287e-02]],\n",
      "\n",
      "         [[ 8.0274e-03, -9.9244e-03,  9.4320e-03],\n",
      "          [ 2.8064e-03,  2.2174e-02, -6.3142e-03],\n",
      "          [-7.4501e-03,  5.6809e-02, -3.0940e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.2182e-03, -1.2504e-02,  1.8376e-02],\n",
      "          [ 6.6300e-03,  3.1926e-03, -5.5482e-03],\n",
      "          [-7.5502e-03, -3.5590e-03,  2.1195e-02]],\n",
      "\n",
      "         [[-2.2975e-02,  1.1704e-02, -5.5784e-04],\n",
      "          [ 1.8214e-02, -9.5722e-03, -2.1152e-03],\n",
      "          [ 4.1358e-02, -2.8319e-03,  3.7769e-03]],\n",
      "\n",
      "         [[-9.0998e-03, -2.0431e-02, -1.7985e-03],\n",
      "          [-1.5559e-02,  4.4778e-02,  1.0857e-02],\n",
      "          [ 4.5258e-03,  2.3690e-02,  3.5134e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9650e-03, -6.9018e-04,  5.1737e-03],\n",
      "          [-3.0738e-03,  4.5087e-03,  1.0360e-03],\n",
      "          [ 2.2299e-02, -3.3854e-03,  4.9482e-02]],\n",
      "\n",
      "         [[ 6.7797e-03, -1.4997e-02, -2.1526e-02],\n",
      "          [ 2.8612e-02,  2.1746e-03, -2.6366e-02],\n",
      "          [ 3.1310e-03,  1.7821e-02, -3.0658e-02]],\n",
      "\n",
      "         [[-1.1876e-02, -1.1969e-02,  8.3984e-03],\n",
      "          [-1.8188e-02, -1.1248e-02,  7.7187e-04],\n",
      "          [ 2.1437e-02,  1.5949e-02, -1.1820e-03]]]])), ('features.17.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('features.19.weight', tensor([[[[-0.0287,  0.0118, -0.0176],\n",
      "          [-0.0047, -0.0287,  0.0001],\n",
      "          [-0.0015, -0.0097,  0.0050]],\n",
      "\n",
      "         [[ 0.0027, -0.0111, -0.0299],\n",
      "          [-0.0034,  0.0029, -0.0090],\n",
      "          [-0.0244,  0.0463, -0.0094]],\n",
      "\n",
      "         [[-0.0095, -0.0242,  0.0172],\n",
      "          [ 0.0044, -0.0441, -0.0294],\n",
      "          [ 0.0250,  0.0088, -0.0006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0196, -0.0484, -0.0070],\n",
      "          [ 0.0095,  0.0378, -0.0235],\n",
      "          [ 0.0371,  0.0025, -0.0075]],\n",
      "\n",
      "         [[-0.0222,  0.0022, -0.0085],\n",
      "          [-0.0269, -0.0029,  0.0076],\n",
      "          [-0.0221, -0.0008, -0.0113]],\n",
      "\n",
      "         [[-0.0290,  0.0014, -0.0009],\n",
      "          [-0.0134,  0.0102,  0.0217],\n",
      "          [-0.0417, -0.0183, -0.0003]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0042,  0.0049, -0.0463],\n",
      "          [ 0.0255, -0.0162, -0.0063],\n",
      "          [-0.0222,  0.0066, -0.0197]],\n",
      "\n",
      "         [[ 0.0243, -0.0355,  0.0146],\n",
      "          [ 0.0144,  0.0046, -0.0103],\n",
      "          [-0.0082,  0.0200,  0.0191]],\n",
      "\n",
      "         [[ 0.0246, -0.0078,  0.0024],\n",
      "          [ 0.0016,  0.0420, -0.0060],\n",
      "          [-0.0049,  0.0315, -0.0035]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0313, -0.0213, -0.0141],\n",
      "          [ 0.0055, -0.0085, -0.0159],\n",
      "          [ 0.0325,  0.0081,  0.0170]],\n",
      "\n",
      "         [[ 0.0130, -0.0025,  0.0479],\n",
      "          [ 0.0230,  0.0196,  0.0141],\n",
      "          [-0.0077,  0.0202, -0.0183]],\n",
      "\n",
      "         [[ 0.0006,  0.0099,  0.0014],\n",
      "          [-0.0362, -0.0040,  0.0133],\n",
      "          [ 0.0075, -0.0050, -0.0098]]],\n",
      "\n",
      "\n",
      "        [[[-0.0053, -0.0146, -0.0130],\n",
      "          [ 0.0091,  0.0261,  0.0118],\n",
      "          [-0.0147, -0.0077,  0.0289]],\n",
      "\n",
      "         [[ 0.0158, -0.0047,  0.0016],\n",
      "          [-0.0162,  0.0061,  0.0059],\n",
      "          [ 0.0326, -0.0238,  0.0057]],\n",
      "\n",
      "         [[ 0.0174, -0.0060,  0.0150],\n",
      "          [-0.0126, -0.0139,  0.0045],\n",
      "          [-0.0166,  0.0374,  0.0052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0381,  0.0190, -0.0502],\n",
      "          [-0.0035,  0.0101, -0.0186],\n",
      "          [ 0.0085,  0.0235, -0.0126]],\n",
      "\n",
      "         [[ 0.0264, -0.0135, -0.0170],\n",
      "          [ 0.0355,  0.0005, -0.0318],\n",
      "          [ 0.0145, -0.0027,  0.0505]],\n",
      "\n",
      "         [[ 0.0099,  0.0182, -0.0132],\n",
      "          [ 0.0535, -0.0167, -0.0209],\n",
      "          [ 0.0333,  0.0150, -0.0288]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0092, -0.0148, -0.0046],\n",
      "          [ 0.0223,  0.0333,  0.0194],\n",
      "          [-0.0122, -0.0111, -0.0067]],\n",
      "\n",
      "         [[ 0.0292, -0.0109, -0.0259],\n",
      "          [-0.0166,  0.0094, -0.0196],\n",
      "          [-0.0094, -0.0124, -0.0184]],\n",
      "\n",
      "         [[-0.0146, -0.0056,  0.0531],\n",
      "          [ 0.0364,  0.0095,  0.0046],\n",
      "          [-0.0022, -0.0123, -0.0369]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0068,  0.0173,  0.0294],\n",
      "          [ 0.0018,  0.0116,  0.0160],\n",
      "          [-0.0205, -0.0271,  0.0450]],\n",
      "\n",
      "         [[ 0.0009, -0.0075, -0.0112],\n",
      "          [ 0.0157, -0.0015,  0.0176],\n",
      "          [-0.0177, -0.0040, -0.0124]],\n",
      "\n",
      "         [[ 0.0263,  0.0145, -0.0051],\n",
      "          [-0.0212,  0.0043, -0.0185],\n",
      "          [ 0.0045, -0.0034,  0.0127]]],\n",
      "\n",
      "\n",
      "        [[[-0.0097, -0.0060, -0.0352],\n",
      "          [ 0.0018,  0.0250,  0.0022],\n",
      "          [ 0.0191,  0.0395, -0.0145]],\n",
      "\n",
      "         [[-0.0251, -0.0025,  0.0315],\n",
      "          [ 0.0079, -0.0088,  0.0039],\n",
      "          [ 0.0389,  0.0279,  0.0011]],\n",
      "\n",
      "         [[ 0.0329, -0.0082,  0.0004],\n",
      "          [ 0.0712, -0.0289,  0.0227],\n",
      "          [-0.0084,  0.0177,  0.0124]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0029, -0.0422, -0.0087],\n",
      "          [-0.0058, -0.0162, -0.0241],\n",
      "          [ 0.0311, -0.0365, -0.0334]],\n",
      "\n",
      "         [[-0.0248, -0.0292,  0.0378],\n",
      "          [-0.0182,  0.0185, -0.0122],\n",
      "          [-0.0249,  0.0097,  0.0011]],\n",
      "\n",
      "         [[ 0.0442, -0.0284, -0.0044],\n",
      "          [-0.0056, -0.0252, -0.0251],\n",
      "          [ 0.0275, -0.0014,  0.0053]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0065,  0.0117,  0.0139],\n",
      "          [ 0.0432, -0.0038, -0.0098],\n",
      "          [ 0.0144, -0.0129,  0.0325]],\n",
      "\n",
      "         [[-0.0349, -0.0063, -0.0094],\n",
      "          [-0.0058,  0.0043, -0.0270],\n",
      "          [-0.0052, -0.0134, -0.0212]],\n",
      "\n",
      "         [[ 0.0025,  0.0109, -0.0557],\n",
      "          [ 0.0189, -0.0009,  0.0008],\n",
      "          [-0.0040,  0.0301, -0.0001]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0311, -0.0258, -0.0302],\n",
      "          [-0.0118, -0.0081, -0.0049],\n",
      "          [-0.0015,  0.0127,  0.0093]],\n",
      "\n",
      "         [[ 0.0161,  0.0278,  0.0042],\n",
      "          [-0.0121,  0.0014, -0.0179],\n",
      "          [-0.0144,  0.0146, -0.0032]],\n",
      "\n",
      "         [[-0.0069, -0.0498, -0.0048],\n",
      "          [ 0.0571, -0.0125,  0.0333],\n",
      "          [ 0.0418,  0.0381, -0.0009]]]])), ('features.19.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('features.21.weight', tensor([[[[ 0.0073,  0.0257,  0.0282],\n",
      "          [-0.0283,  0.0167,  0.0053],\n",
      "          [ 0.0256,  0.0067,  0.0131]],\n",
      "\n",
      "         [[-0.0236,  0.0077,  0.0106],\n",
      "          [-0.0145, -0.0231, -0.0098],\n",
      "          [-0.0217, -0.0130, -0.0140]],\n",
      "\n",
      "         [[ 0.0144, -0.0192,  0.0054],\n",
      "          [-0.0160,  0.0099,  0.0049],\n",
      "          [-0.0173, -0.0256,  0.0014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0002, -0.0429, -0.0002],\n",
      "          [-0.0288, -0.0024,  0.0028],\n",
      "          [ 0.0488, -0.0024, -0.0080]],\n",
      "\n",
      "         [[ 0.0215, -0.0179, -0.0098],\n",
      "          [ 0.0192,  0.0114,  0.0198],\n",
      "          [ 0.0372,  0.0241, -0.0119]],\n",
      "\n",
      "         [[ 0.0006, -0.0081, -0.0034],\n",
      "          [-0.0016, -0.0084, -0.0346],\n",
      "          [-0.0135, -0.0060, -0.0064]]],\n",
      "\n",
      "\n",
      "        [[[-0.0024,  0.0262,  0.0373],\n",
      "          [ 0.0161, -0.0114, -0.0022],\n",
      "          [-0.0122, -0.0254,  0.0429]],\n",
      "\n",
      "         [[ 0.0092, -0.0585,  0.0214],\n",
      "          [ 0.0338,  0.0314,  0.0346],\n",
      "          [-0.0203, -0.0265,  0.0004]],\n",
      "\n",
      "         [[-0.0392,  0.0111, -0.0376],\n",
      "          [-0.0278, -0.0519, -0.0007],\n",
      "          [-0.0227, -0.0345,  0.0319]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0191, -0.0352,  0.0217],\n",
      "          [-0.0281, -0.0020, -0.0253],\n",
      "          [ 0.0282, -0.0081, -0.0164]],\n",
      "\n",
      "         [[-0.0064,  0.0257, -0.0095],\n",
      "          [ 0.0104,  0.0043, -0.0376],\n",
      "          [ 0.0201, -0.0033, -0.0015]],\n",
      "\n",
      "         [[ 0.0463, -0.0124,  0.0136],\n",
      "          [ 0.0002,  0.0288,  0.0122],\n",
      "          [-0.0277, -0.0215, -0.0072]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0054, -0.0099,  0.0219],\n",
      "          [-0.0181, -0.0206,  0.0080],\n",
      "          [-0.0121, -0.0351, -0.0151]],\n",
      "\n",
      "         [[-0.0068,  0.0157, -0.0122],\n",
      "          [ 0.0125, -0.0254,  0.0189],\n",
      "          [-0.0278, -0.0076, -0.0214]],\n",
      "\n",
      "         [[ 0.0067,  0.0095, -0.0015],\n",
      "          [-0.0124, -0.0158,  0.0136],\n",
      "          [ 0.0249, -0.0035,  0.0176]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0247, -0.0021, -0.0366],\n",
      "          [-0.0215,  0.0079,  0.0301],\n",
      "          [ 0.0302,  0.0006, -0.0545]],\n",
      "\n",
      "         [[ 0.0145,  0.0184,  0.0311],\n",
      "          [-0.0075, -0.0204,  0.0024],\n",
      "          [ 0.0014, -0.0043,  0.0205]],\n",
      "\n",
      "         [[ 0.0223,  0.0007, -0.0113],\n",
      "          [-0.0039,  0.0013,  0.0125],\n",
      "          [ 0.0107,  0.0224,  0.0082]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0062, -0.0319,  0.0110],\n",
      "          [ 0.0469, -0.0001,  0.0031],\n",
      "          [-0.0160,  0.0173, -0.0037]],\n",
      "\n",
      "         [[-0.0018,  0.0111, -0.0117],\n",
      "          [-0.0427,  0.0301, -0.0406],\n",
      "          [-0.0018, -0.0246,  0.0205]],\n",
      "\n",
      "         [[-0.0126, -0.0248,  0.0449],\n",
      "          [ 0.0061, -0.0020, -0.0061],\n",
      "          [ 0.0449,  0.0250, -0.0031]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0028,  0.0432, -0.0003],\n",
      "          [ 0.0037,  0.0292,  0.0067],\n",
      "          [-0.0076,  0.0094,  0.0122]],\n",
      "\n",
      "         [[ 0.0137, -0.0165,  0.0366],\n",
      "          [-0.0228,  0.0271,  0.0128],\n",
      "          [ 0.0162, -0.0136,  0.0321]],\n",
      "\n",
      "         [[ 0.0062,  0.0202,  0.0244],\n",
      "          [-0.0119, -0.0190,  0.0010],\n",
      "          [ 0.0341,  0.0010, -0.0060]]],\n",
      "\n",
      "\n",
      "        [[[-0.0235, -0.0123,  0.0149],\n",
      "          [ 0.0087, -0.0381, -0.0037],\n",
      "          [-0.0066, -0.0284,  0.0050]],\n",
      "\n",
      "         [[-0.0214,  0.0346,  0.0103],\n",
      "          [ 0.0211, -0.0254,  0.0249],\n",
      "          [-0.0057, -0.0044,  0.0073]],\n",
      "\n",
      "         [[-0.0063,  0.0184,  0.0317],\n",
      "          [-0.0117, -0.0010,  0.0139],\n",
      "          [ 0.0365, -0.0196,  0.0273]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0054,  0.0033,  0.0157],\n",
      "          [ 0.0045,  0.0360, -0.0449],\n",
      "          [ 0.0009, -0.0149,  0.0034]],\n",
      "\n",
      "         [[ 0.0168, -0.0173, -0.0201],\n",
      "          [ 0.0160, -0.0091, -0.0106],\n",
      "          [-0.0038, -0.0142, -0.0078]],\n",
      "\n",
      "         [[ 0.0228,  0.0072,  0.0331],\n",
      "          [ 0.0333, -0.0077,  0.0219],\n",
      "          [ 0.0078,  0.0019,  0.0272]]],\n",
      "\n",
      "\n",
      "        [[[-0.0065, -0.0004,  0.0059],\n",
      "          [-0.0057, -0.0268, -0.0272],\n",
      "          [-0.0134,  0.0056, -0.0114]],\n",
      "\n",
      "         [[-0.0080, -0.0140, -0.0155],\n",
      "          [ 0.0196, -0.0248, -0.0208],\n",
      "          [ 0.0206,  0.0083,  0.0180]],\n",
      "\n",
      "         [[ 0.0042, -0.0398, -0.0381],\n",
      "          [-0.0056,  0.0082, -0.0165],\n",
      "          [-0.0272,  0.0139,  0.0216]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0179, -0.0710,  0.0226],\n",
      "          [-0.0077, -0.0476,  0.0133],\n",
      "          [ 0.0115,  0.0035,  0.0109]],\n",
      "\n",
      "         [[ 0.0137,  0.0014,  0.0130],\n",
      "          [ 0.0212,  0.0180,  0.0218],\n",
      "          [-0.0113,  0.0011, -0.0249]],\n",
      "\n",
      "         [[-0.0038, -0.0364,  0.0037],\n",
      "          [ 0.0123,  0.0071, -0.0160],\n",
      "          [-0.0082, -0.0088, -0.0315]]]])), ('features.21.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('features.24.weight', tensor([[[[ 4.4139e-03, -1.1790e-02, -5.8919e-03],\n",
      "          [ 2.5536e-02,  2.3378e-02, -1.4968e-02],\n",
      "          [-2.6706e-03, -1.9048e-02,  1.4245e-02]],\n",
      "\n",
      "         [[-8.5705e-03, -3.9346e-02, -1.9782e-02],\n",
      "          [ 2.7233e-02,  2.6543e-02,  1.4646e-02],\n",
      "          [ 1.2960e-02,  9.2722e-03, -1.8193e-03]],\n",
      "\n",
      "         [[-9.9645e-03,  1.6960e-02, -8.0693e-03],\n",
      "          [-1.8161e-02,  3.5976e-03, -1.6803e-02],\n",
      "          [ 8.7888e-03, -3.0038e-02,  8.3387e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0128e-03, -3.2630e-02, -9.4621e-03],\n",
      "          [-3.1101e-02, -9.9281e-03, -4.7932e-03],\n",
      "          [-1.8536e-02,  1.4546e-04, -1.9674e-02]],\n",
      "\n",
      "         [[ 3.3006e-02,  1.8718e-02, -5.7918e-02],\n",
      "          [ 2.9518e-02, -2.4184e-02,  1.4872e-02],\n",
      "          [ 2.4696e-02,  7.0396e-03,  5.3155e-03]],\n",
      "\n",
      "         [[-4.4328e-03,  2.1612e-02, -2.5334e-02],\n",
      "          [-4.3900e-03,  1.8172e-02, -1.6491e-02],\n",
      "          [-6.5093e-03, -3.6049e-02,  2.3232e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4065e-02,  5.7091e-03, -1.5178e-02],\n",
      "          [ 3.1930e-02, -2.0577e-05, -2.8929e-03],\n",
      "          [ 4.7086e-03,  2.7333e-02,  9.5228e-03]],\n",
      "\n",
      "         [[-1.7636e-02,  2.2691e-02, -3.6268e-03],\n",
      "          [-3.0758e-02, -1.1825e-02, -9.4367e-03],\n",
      "          [ 1.2725e-02, -4.0208e-03,  1.5523e-02]],\n",
      "\n",
      "         [[ 4.1983e-02,  1.6394e-02, -8.4423e-03],\n",
      "          [ 2.0813e-02,  2.4824e-03, -1.0597e-02],\n",
      "          [ 7.7995e-03, -4.1313e-02,  6.5166e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1384e-02,  2.9245e-02, -1.2007e-02],\n",
      "          [-9.3143e-03, -4.5394e-02,  2.9730e-02],\n",
      "          [-1.2281e-02,  2.1481e-02, -9.3108e-03]],\n",
      "\n",
      "         [[ 4.9849e-03, -1.9803e-03, -2.0778e-03],\n",
      "          [ 4.5571e-03,  1.1003e-02,  9.3186e-03],\n",
      "          [-4.8695e-03, -2.3445e-02, -1.9331e-02]],\n",
      "\n",
      "         [[ 2.4593e-02, -2.3527e-02, -2.0184e-02],\n",
      "          [ 1.1399e-02,  3.1266e-03,  2.2745e-02],\n",
      "          [-5.4283e-03,  5.8386e-03, -4.0148e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.0261e-02,  3.3362e-02, -9.4928e-03],\n",
      "          [ 6.7953e-03, -6.6075e-03,  1.5411e-02],\n",
      "          [-7.8562e-03,  7.8701e-03,  2.7145e-02]],\n",
      "\n",
      "         [[ 1.3684e-02,  9.2703e-03, -8.6952e-03],\n",
      "          [ 2.3835e-02,  2.6430e-02, -1.6976e-02],\n",
      "          [ 2.4246e-02,  3.4682e-02,  1.1483e-02]],\n",
      "\n",
      "         [[-2.3648e-02,  2.9076e-02,  5.1161e-03],\n",
      "          [-1.2088e-02, -3.9844e-03,  1.6960e-02],\n",
      "          [-9.6439e-03, -1.0162e-02, -3.3090e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2847e-03, -2.6774e-02,  2.5058e-02],\n",
      "          [ 6.9562e-02,  1.4058e-02,  2.6681e-02],\n",
      "          [-6.7811e-03, -3.7118e-03, -1.7672e-02]],\n",
      "\n",
      "         [[-3.5642e-02, -4.9859e-03,  2.0640e-02],\n",
      "          [ 1.6194e-02,  2.6879e-03,  1.4762e-03],\n",
      "          [ 1.5981e-02, -8.9546e-03,  3.2181e-03]],\n",
      "\n",
      "         [[-6.2787e-03, -2.0935e-02,  5.7300e-03],\n",
      "          [ 4.6963e-03, -2.2517e-02,  1.1008e-02],\n",
      "          [-3.6225e-02, -2.2809e-02, -1.3054e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.5005e-03, -7.2045e-03, -2.9754e-02],\n",
      "          [ 2.2986e-03,  1.0520e-03,  3.7405e-03],\n",
      "          [ 2.2899e-02,  1.4394e-02,  1.2463e-02]],\n",
      "\n",
      "         [[-4.2083e-02,  1.5356e-02, -1.6664e-02],\n",
      "          [ 2.6349e-02, -8.8224e-03, -6.8574e-03],\n",
      "          [-4.2138e-03,  1.0117e-02,  6.1798e-03]],\n",
      "\n",
      "         [[-2.3459e-02, -1.5674e-02, -5.0234e-02],\n",
      "          [-5.5747e-03, -1.1873e-02, -2.2994e-02],\n",
      "          [ 1.9651e-02,  3.2847e-02, -7.1510e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5616e-02, -1.1973e-02, -4.7994e-03],\n",
      "          [ 7.6617e-04, -2.6854e-02, -1.6452e-02],\n",
      "          [-3.2775e-02, -6.4185e-03,  2.5588e-02]],\n",
      "\n",
      "         [[ 6.4883e-03,  7.5846e-03, -3.6873e-02],\n",
      "          [-6.8940e-03, -3.1724e-03,  3.3657e-03],\n",
      "          [-2.9837e-03,  1.1895e-03,  3.6600e-02]],\n",
      "\n",
      "         [[ 1.7726e-02,  1.4868e-02,  9.4435e-03],\n",
      "          [-1.5301e-02,  1.0535e-02, -1.2606e-03],\n",
      "          [ 1.9098e-02, -2.5352e-02,  2.7809e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5372e-02, -3.4387e-02, -7.8097e-03],\n",
      "          [-2.9510e-03, -3.6767e-02,  3.5891e-02],\n",
      "          [ 2.0748e-03,  2.5089e-02, -4.8764e-03]],\n",
      "\n",
      "         [[ 3.6387e-02, -1.1795e-03, -1.0660e-02],\n",
      "          [-1.2834e-02, -2.2483e-02, -4.4173e-03],\n",
      "          [-2.4298e-02,  1.8748e-02, -1.1211e-02]],\n",
      "\n",
      "         [[ 1.5142e-02, -3.4627e-02,  1.1231e-02],\n",
      "          [-5.7168e-03, -5.6466e-03, -1.2747e-02],\n",
      "          [-2.8890e-02,  3.9157e-02, -2.6380e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7057e-03,  1.0486e-02,  2.6485e-02],\n",
      "          [ 2.9101e-02, -1.4863e-02,  1.0123e-02],\n",
      "          [ 2.6184e-02, -1.9687e-02, -2.0642e-02]],\n",
      "\n",
      "         [[ 1.5983e-04,  3.4014e-02,  2.1482e-02],\n",
      "          [ 4.6727e-02,  1.5941e-02,  2.3560e-02],\n",
      "          [-1.8712e-02,  2.9075e-02,  9.9470e-03]],\n",
      "\n",
      "         [[-3.7601e-02,  3.0248e-03,  1.7833e-02],\n",
      "          [ 2.6566e-02, -2.9189e-02,  5.2624e-03],\n",
      "          [-7.1660e-03,  2.3804e-02, -3.4850e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4724e-03, -1.4320e-02, -1.9203e-03],\n",
      "          [ 2.7736e-02, -2.2328e-02, -1.8567e-02],\n",
      "          [ 3.0091e-02, -3.6964e-03, -6.0846e-03]],\n",
      "\n",
      "         [[-1.9638e-02,  2.7072e-02, -2.7806e-03],\n",
      "          [-2.0427e-02,  1.4472e-03,  5.5313e-04],\n",
      "          [-2.1259e-02, -9.1961e-03,  2.1305e-02]],\n",
      "\n",
      "         [[ 8.0042e-03,  2.6778e-02, -1.6323e-02],\n",
      "          [ 3.5089e-04, -4.9647e-02, -2.2565e-02],\n",
      "          [ 1.7065e-02,  1.4680e-03, -1.4234e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.3329e-02, -5.3790e-03,  4.5731e-03],\n",
      "          [ 4.1723e-03,  1.0477e-02, -2.6377e-03],\n",
      "          [ 9.9389e-03,  1.6898e-02,  7.0590e-04]],\n",
      "\n",
      "         [[-7.9182e-03,  5.7460e-03, -2.1806e-02],\n",
      "          [-4.2489e-02,  2.7433e-02, -2.3667e-03],\n",
      "          [ 1.4859e-02,  1.9317e-03,  2.7321e-02]],\n",
      "\n",
      "         [[ 3.0082e-02,  2.3122e-02, -7.2049e-03],\n",
      "          [-2.4658e-02,  5.7622e-03, -5.8253e-03],\n",
      "          [ 1.5331e-03,  5.4762e-03, -2.8798e-02]]]])), ('features.24.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('features.26.weight', tensor([[[[-1.3595e-02,  4.7354e-03, -1.0871e-03],\n",
      "          [ 2.4058e-03, -2.1290e-02,  8.1509e-03],\n",
      "          [-1.0648e-02,  1.5081e-02,  2.4422e-02]],\n",
      "\n",
      "         [[ 3.9965e-02, -1.8593e-02, -7.5732e-03],\n",
      "          [-2.0483e-02, -3.8945e-03, -1.4306e-02],\n",
      "          [ 3.6904e-02, -4.1743e-02,  2.0924e-02]],\n",
      "\n",
      "         [[ 1.3488e-02,  1.3473e-02, -4.6620e-02],\n",
      "          [-2.3061e-03,  9.5969e-03, -1.1231e-02],\n",
      "          [-1.8010e-02, -2.9332e-02, -7.7639e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4175e-02,  1.6211e-02, -4.4055e-02],\n",
      "          [ 7.1981e-04,  3.3908e-02,  3.9725e-02],\n",
      "          [-6.8925e-03,  3.1018e-03, -1.2288e-02]],\n",
      "\n",
      "         [[-1.6515e-02, -1.8472e-03, -6.3128e-03],\n",
      "          [-2.0364e-02, -7.9743e-03, -3.0309e-02],\n",
      "          [-4.7667e-02,  1.3344e-03,  3.4805e-02]],\n",
      "\n",
      "         [[ 3.1800e-02, -9.4330e-03,  2.7623e-02],\n",
      "          [-1.7184e-02, -3.2891e-03,  1.3672e-02],\n",
      "          [ 1.6366e-02, -3.8358e-02,  2.9241e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.5555e-03, -9.7490e-03, -2.4482e-02],\n",
      "          [ 2.2314e-03, -2.1646e-03, -3.6683e-02],\n",
      "          [-2.0806e-03, -3.9109e-03, -7.3461e-03]],\n",
      "\n",
      "         [[ 1.4608e-03, -1.7872e-02,  3.4338e-03],\n",
      "          [-1.3528e-02,  3.3950e-03,  2.2069e-02],\n",
      "          [-1.1404e-02, -1.1412e-02, -1.7363e-02]],\n",
      "\n",
      "         [[ 9.3509e-03, -8.9302e-03,  2.7042e-02],\n",
      "          [-4.3818e-03,  1.0560e-02,  1.2987e-03],\n",
      "          [-9.9823e-03,  2.7071e-03, -4.1122e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6163e-03,  2.0012e-02, -2.5999e-03],\n",
      "          [-2.4896e-02,  2.9378e-02, -4.2108e-02],\n",
      "          [ 1.5615e-02,  1.6807e-02,  1.9322e-02]],\n",
      "\n",
      "         [[ 2.1709e-02, -9.9444e-03,  1.2148e-02],\n",
      "          [ 2.4841e-02,  6.0691e-03,  1.2206e-02],\n",
      "          [ 2.2703e-02, -5.9264e-03,  1.3925e-02]],\n",
      "\n",
      "         [[-5.2979e-03, -3.3101e-02, -2.5091e-02],\n",
      "          [-1.7063e-03, -1.5985e-02, -1.3688e-03],\n",
      "          [-3.7905e-03,  1.1592e-02,  2.2344e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5434e-02,  1.8889e-02,  7.9745e-03],\n",
      "          [ 3.4772e-04,  5.5453e-03, -4.2217e-03],\n",
      "          [ 9.3234e-03,  2.8502e-02, -9.0193e-03]],\n",
      "\n",
      "         [[-4.1318e-03,  2.4217e-02,  2.9515e-03],\n",
      "          [-7.2971e-03, -1.8845e-02,  4.0271e-02],\n",
      "          [ 3.5004e-02, -1.6539e-02, -1.3520e-02]],\n",
      "\n",
      "         [[ 1.1194e-02, -2.5105e-03, -2.9535e-02],\n",
      "          [ 8.6535e-04, -3.0442e-03, -5.5627e-03],\n",
      "          [-1.2033e-02,  2.2137e-02,  2.5243e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9649e-02,  1.9545e-02,  2.9340e-02],\n",
      "          [ 3.8336e-03, -1.3360e-02, -1.3195e-03],\n",
      "          [-2.7007e-02,  1.1687e-02,  3.3056e-02]],\n",
      "\n",
      "         [[-1.2718e-02,  8.7218e-03, -8.9667e-03],\n",
      "          [ 1.7427e-02,  1.9069e-02, -2.4600e-02],\n",
      "          [ 1.0189e-02,  1.0911e-02, -4.6903e-02]],\n",
      "\n",
      "         [[ 2.9432e-02, -1.3765e-02, -5.1282e-03],\n",
      "          [-1.9984e-02, -6.8462e-03,  7.4332e-03],\n",
      "          [-1.0773e-02,  1.7299e-02, -3.6239e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.9232e-02,  2.6641e-02, -3.7249e-02],\n",
      "          [ 4.7608e-03, -7.9190e-04,  3.6379e-03],\n",
      "          [ 3.1580e-02, -1.0480e-02, -1.4594e-02]],\n",
      "\n",
      "         [[-5.7172e-03,  2.0656e-02, -2.2807e-02],\n",
      "          [ 5.8865e-02,  9.0573e-03,  2.5673e-03],\n",
      "          [ 2.0823e-02, -1.4201e-02,  4.8916e-03]],\n",
      "\n",
      "         [[ 1.2403e-02, -2.8216e-02, -1.9630e-02],\n",
      "          [ 3.8774e-02,  2.3884e-02, -1.0754e-02],\n",
      "          [ 1.1714e-02, -2.0429e-02, -1.6859e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6150e-02,  1.0201e-02,  3.1992e-03],\n",
      "          [ 1.0470e-02,  2.5982e-02, -1.4617e-02],\n",
      "          [-9.4759e-03, -7.8804e-03, -1.0712e-02]],\n",
      "\n",
      "         [[-8.9926e-03,  2.3853e-02,  5.4626e-03],\n",
      "          [-3.7738e-03, -6.4484e-03,  1.5544e-02],\n",
      "          [ 1.0356e-02, -5.3259e-03, -1.2659e-02]],\n",
      "\n",
      "         [[ 9.3043e-03, -2.7697e-02, -2.1313e-02],\n",
      "          [-1.6792e-02, -1.0323e-02, -3.1831e-02],\n",
      "          [-1.9380e-02, -5.7206e-03, -2.7183e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7805e-02, -3.7700e-02, -1.7421e-02],\n",
      "          [-1.0219e-02, -2.3841e-02, -1.2394e-02],\n",
      "          [ 1.0025e-02,  4.4221e-03, -2.0620e-02]],\n",
      "\n",
      "         [[-1.9333e-03, -1.4203e-03, -1.5354e-03],\n",
      "          [-4.2562e-02,  6.5410e-04, -1.0999e-02],\n",
      "          [ 1.7518e-02, -6.9328e-03,  2.4165e-03]],\n",
      "\n",
      "         [[-3.2730e-02,  2.0834e-02, -2.1484e-02],\n",
      "          [ 2.2395e-02,  2.9646e-05,  4.3297e-03],\n",
      "          [-2.0939e-02, -2.3567e-03, -1.4395e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7700e-02, -3.3870e-02,  4.1829e-02],\n",
      "          [ 1.8181e-02,  3.0825e-02, -1.6417e-02],\n",
      "          [-3.1889e-02, -2.2853e-02,  8.5902e-03]],\n",
      "\n",
      "         [[ 9.9513e-03,  9.3649e-03,  2.4220e-02],\n",
      "          [-4.8388e-02,  1.7983e-02, -4.1232e-03],\n",
      "          [-5.3359e-04, -3.4958e-03, -1.1072e-03]],\n",
      "\n",
      "         [[-7.3572e-03,  2.5589e-02,  5.8928e-02],\n",
      "          [ 7.2595e-03,  1.5097e-02,  8.5200e-03],\n",
      "          [-4.3093e-02, -4.2702e-02, -3.6303e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9680e-02,  5.9558e-03, -3.0871e-02],\n",
      "          [-4.1054e-02,  9.4873e-03, -3.9841e-03],\n",
      "          [ 3.0549e-03, -2.4588e-02,  1.7093e-02]],\n",
      "\n",
      "         [[-1.5950e-02,  3.8504e-02, -2.2173e-02],\n",
      "          [-1.4160e-02, -4.6591e-03,  6.4751e-03],\n",
      "          [ 1.0889e-02, -5.0451e-03, -1.3942e-02]],\n",
      "\n",
      "         [[ 9.5828e-03, -5.9358e-03, -4.3187e-02],\n",
      "          [ 2.6451e-02,  2.0893e-02, -1.4110e-04],\n",
      "          [ 1.2348e-02, -9.0955e-03,  3.1468e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1473e-02, -1.3872e-03, -9.4470e-03],\n",
      "          [ 2.9897e-04, -1.0811e-02, -1.2993e-02],\n",
      "          [ 1.6493e-02,  1.6041e-02, -1.1337e-02]],\n",
      "\n",
      "         [[-1.3606e-02,  2.6695e-02, -4.1907e-03],\n",
      "          [ 1.6099e-02,  6.1461e-03, -8.9331e-03],\n",
      "          [ 1.1087e-03,  2.3611e-02,  1.8712e-02]],\n",
      "\n",
      "         [[ 7.3524e-03, -1.1357e-02, -3.0800e-03],\n",
      "          [-2.5091e-03,  8.5004e-03, -1.1661e-02],\n",
      "          [ 2.4411e-02, -3.8054e-02, -4.7073e-03]]]])), ('features.26.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('features.28.weight', tensor([[[[ 4.7677e-02, -1.3230e-02,  8.1548e-03],\n",
      "          [-4.0352e-03,  1.0282e-02, -1.1553e-02],\n",
      "          [ 4.1054e-03, -2.6963e-03,  4.9709e-02]],\n",
      "\n",
      "         [[ 1.1410e-02, -1.0908e-02, -6.3225e-03],\n",
      "          [-2.3036e-02,  7.8924e-03,  3.2619e-02],\n",
      "          [-3.1066e-03, -1.1354e-03,  1.2378e-02]],\n",
      "\n",
      "         [[ 1.6013e-02,  2.2473e-02,  2.1987e-02],\n",
      "          [ 3.1898e-04,  2.8984e-02,  5.2172e-04],\n",
      "          [-1.1020e-02, -2.5219e-02,  3.2607e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.3913e-03,  1.4033e-02,  1.4383e-02],\n",
      "          [ 1.0086e-02, -3.1807e-02,  8.8377e-03],\n",
      "          [ 5.3031e-02, -3.4593e-02, -3.8908e-03]],\n",
      "\n",
      "         [[-3.5474e-02, -2.8141e-02,  1.2112e-03],\n",
      "          [ 8.1246e-03,  1.2957e-02, -1.4954e-02],\n",
      "          [-1.1236e-02,  3.0175e-02,  1.7308e-02]],\n",
      "\n",
      "         [[ 1.8624e-02,  2.6223e-02,  1.4721e-02],\n",
      "          [-1.2343e-02,  2.1278e-02,  4.8199e-03],\n",
      "          [-1.8735e-02, -3.1860e-02, -8.4439e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2671e-02,  1.2143e-02, -6.4075e-03],\n",
      "          [-1.6412e-03,  7.2491e-03, -1.6929e-02],\n",
      "          [ 1.4169e-02, -3.5377e-02, -6.4200e-03]],\n",
      "\n",
      "         [[ 2.3317e-02,  2.7362e-03,  1.4620e-02],\n",
      "          [ 1.8331e-02, -2.3135e-02, -1.8348e-02],\n",
      "          [-4.3674e-03,  6.0306e-03, -1.1699e-02]],\n",
      "\n",
      "         [[-4.5525e-04, -8.6345e-03,  2.0143e-04],\n",
      "          [ 1.7412e-02,  2.8279e-02, -3.8840e-02],\n",
      "          [-1.7187e-02,  2.9076e-02,  1.2897e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9473e-03,  7.8987e-04, -1.4081e-02],\n",
      "          [ 2.1880e-02, -4.0299e-03,  2.0433e-02],\n",
      "          [-1.4559e-02, -2.4871e-02,  1.3585e-02]],\n",
      "\n",
      "         [[ 2.0810e-02,  1.0999e-02, -8.1414e-03],\n",
      "          [-8.9681e-03,  2.3177e-02,  4.1862e-02],\n",
      "          [ 2.4910e-02, -1.8156e-02, -1.2740e-02]],\n",
      "\n",
      "         [[-1.7978e-02, -1.6478e-02, -1.7488e-03],\n",
      "          [ 1.4865e-02, -2.4394e-02, -3.1158e-02],\n",
      "          [ 9.5260e-03, -3.0758e-02, -2.1305e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7811e-02,  1.9848e-03, -4.8545e-03],\n",
      "          [-1.7618e-02, -3.9652e-02,  3.3693e-02],\n",
      "          [ 2.2586e-03, -6.8487e-03,  2.3916e-02]],\n",
      "\n",
      "         [[-2.1910e-02,  6.2350e-03, -2.1238e-02],\n",
      "          [-6.8249e-03, -3.9368e-02,  2.8828e-02],\n",
      "          [ 3.4268e-02,  2.8090e-03,  2.2948e-02]],\n",
      "\n",
      "         [[-5.3779e-02, -3.1862e-02,  4.7030e-02],\n",
      "          [ 1.8758e-03, -1.0329e-02,  1.4635e-02],\n",
      "          [ 2.4078e-02, -3.1616e-02,  7.8137e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5932e-02, -6.8133e-03, -1.7797e-02],\n",
      "          [ 2.2860e-02, -4.5914e-03,  6.2440e-03],\n",
      "          [-3.1331e-02, -3.1233e-02,  1.3869e-02]],\n",
      "\n",
      "         [[-2.7371e-02,  5.9546e-03,  1.6451e-02],\n",
      "          [-1.4397e-02, -1.6585e-02,  1.1014e-02],\n",
      "          [-1.7672e-02,  2.0104e-02,  3.4521e-02]],\n",
      "\n",
      "         [[ 2.9042e-02,  8.6480e-03,  3.2373e-02],\n",
      "          [-4.9724e-02, -2.8699e-02, -2.2607e-02],\n",
      "          [ 3.1209e-02,  7.7053e-03,  2.5630e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.4125e-03, -1.7887e-02, -1.3045e-03],\n",
      "          [ 9.0274e-03, -3.3346e-02,  6.6509e-03],\n",
      "          [ 6.5677e-03, -3.5715e-02,  3.7248e-03]],\n",
      "\n",
      "         [[ 4.2841e-02, -4.4612e-02, -3.3910e-03],\n",
      "          [-1.5835e-03, -1.1928e-02,  1.6730e-02],\n",
      "          [ 2.0188e-02,  1.1934e-02, -2.1247e-03]],\n",
      "\n",
      "         [[-1.5246e-02, -1.9605e-02, -9.4908e-03],\n",
      "          [-5.0231e-03,  2.9539e-02,  7.4371e-04],\n",
      "          [-7.0291e-03,  1.9794e-02,  3.1886e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4785e-03, -2.7030e-02, -5.5179e-03],\n",
      "          [ 7.0882e-03, -7.2558e-03,  4.1875e-02],\n",
      "          [-3.7692e-02, -1.0297e-02,  2.1864e-02]],\n",
      "\n",
      "         [[ 3.7117e-03,  1.0928e-02,  1.8433e-02],\n",
      "          [-2.3541e-02,  2.4344e-02, -1.1303e-02],\n",
      "          [ 2.7861e-02,  2.1177e-02, -3.5979e-02]],\n",
      "\n",
      "         [[ 3.0497e-02, -1.3015e-02, -1.6354e-02],\n",
      "          [ 1.5330e-02, -1.2112e-02,  1.0714e-02],\n",
      "          [-1.4592e-02,  3.0647e-02, -3.3966e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4310e-02,  4.7333e-02,  1.1107e-02],\n",
      "          [-1.6226e-02, -4.8789e-02,  1.7594e-02],\n",
      "          [ 1.4929e-03,  2.4847e-02,  2.9359e-02]],\n",
      "\n",
      "         [[ 3.7583e-02, -3.2330e-02,  1.7395e-02],\n",
      "          [-1.8329e-04,  2.6056e-02, -7.6507e-03],\n",
      "          [-8.6336e-03,  3.9711e-03, -2.8567e-02]],\n",
      "\n",
      "         [[-4.2859e-02, -1.7793e-02,  2.5614e-02],\n",
      "          [ 1.0095e-02,  2.0351e-02,  1.1280e-02],\n",
      "          [-3.5378e-02, -3.9780e-02,  4.0476e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.8776e-03,  3.4930e-03,  1.0139e-02],\n",
      "          [ 2.0268e-02, -1.7010e-02, -2.9081e-03],\n",
      "          [ 6.2959e-03, -2.3386e-03,  1.9025e-02]],\n",
      "\n",
      "         [[-8.4614e-03,  2.9688e-02,  1.9660e-02],\n",
      "          [-1.0650e-02,  2.7689e-02, -1.2784e-02],\n",
      "          [ 1.9926e-02,  8.9240e-03,  4.3321e-03]],\n",
      "\n",
      "         [[ 7.8540e-03, -3.1220e-02,  5.1344e-03],\n",
      "          [-4.8948e-04, -1.7988e-04, -2.8152e-02],\n",
      "          [ 2.9947e-02, -1.9744e-02, -3.9572e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0109e-03,  1.1147e-02, -9.3618e-03],\n",
      "          [-3.9373e-02,  1.7342e-02,  9.6219e-03],\n",
      "          [-8.5551e-03,  2.5282e-02,  6.0644e-02]],\n",
      "\n",
      "         [[-1.7084e-02, -1.3949e-02,  2.0746e-02],\n",
      "          [-9.2763e-03,  5.8794e-03,  1.4759e-02],\n",
      "          [-1.1985e-02, -1.4836e-02, -1.6946e-02]],\n",
      "\n",
      "         [[ 9.8732e-03, -2.3482e-02,  4.9252e-02],\n",
      "          [-4.2687e-02, -5.2094e-03, -2.0529e-02],\n",
      "          [-2.2038e-02, -1.1615e-03, -4.8120e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9964e-02, -1.3851e-02,  1.8069e-02],\n",
      "          [-2.0191e-05, -9.6384e-03, -1.3346e-02],\n",
      "          [ 1.2436e-02, -8.7784e-03,  3.9046e-03]],\n",
      "\n",
      "         [[ 2.2711e-02,  3.3432e-02, -1.8907e-02],\n",
      "          [ 4.0572e-03, -2.3100e-02,  1.0936e-02],\n",
      "          [-1.9602e-02,  8.3197e-03,  4.1581e-03]],\n",
      "\n",
      "         [[ 2.0331e-02, -1.1299e-02, -1.9595e-02],\n",
      "          [-4.7769e-03, -4.4373e-03,  2.2468e-02],\n",
      "          [ 3.6742e-03, -1.0798e-02, -2.3690e-02]]]])), ('features.28.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('classifier.0.weight', tensor([[ 8.7326e-03, -2.2454e-03,  3.9680e-05,  ...,  8.6021e-03,\n",
      "          8.6066e-03, -1.1813e-04],\n",
      "        [-1.7061e-02,  2.6901e-03, -2.2031e-03,  ...,  7.9405e-03,\n",
      "         -1.2853e-03, -4.1104e-03],\n",
      "        [-1.1634e-02, -8.3620e-03,  5.3148e-03,  ...,  1.1541e-02,\n",
      "         -2.6899e-03,  4.6875e-03],\n",
      "        ...,\n",
      "        [-7.0797e-03,  2.9927e-03, -2.0842e-02,  ..., -2.1298e-03,\n",
      "          7.6661e-03, -7.3799e-04],\n",
      "        [ 1.5296e-03,  1.7415e-02,  4.8609e-03,  ..., -5.8851e-03,\n",
      "          3.6787e-03,  4.7664e-04],\n",
      "        [ 1.3556e-02,  3.8480e-03, -4.9480e-03,  ..., -7.5195e-03,\n",
      "          1.6858e-02,  1.5710e-03]])), ('classifier.0.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('classifier.3.weight', tensor([[-0.0028,  0.0042, -0.0102,  ...,  0.0115,  0.0079,  0.0099],\n",
      "        [-0.0118, -0.0157,  0.0081,  ..., -0.0061, -0.0019,  0.0206],\n",
      "        [ 0.0034,  0.0021, -0.0004,  ..., -0.0041,  0.0034,  0.0033],\n",
      "        ...,\n",
      "        [ 0.0141, -0.0004, -0.0161,  ...,  0.0141, -0.0144,  0.0017],\n",
      "        [ 0.0007, -0.0061, -0.0108,  ..., -0.0064,  0.0024,  0.0091],\n",
      "        [ 0.0135, -0.0150, -0.0102,  ..., -0.0085, -0.0137, -0.0056]])), ('classifier.3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('classifier.6.weight', tensor([[ 4.3585e-03, -7.9109e-03, -4.3370e-03,  ...,  4.7107e-03,\n",
      "          1.9101e-02,  3.0828e-03],\n",
      "        [-7.8912e-03,  6.3033e-03,  8.5372e-03,  ...,  3.2390e-04,\n",
      "          7.0038e-03, -2.0247e-03],\n",
      "        [-5.1779e-03, -8.0205e-03,  1.0307e-03,  ...,  1.1701e-02,\n",
      "          5.9549e-03,  2.2098e-02],\n",
      "        ...,\n",
      "        [-4.6863e-05, -1.5645e-02,  1.1493e-02,  ..., -1.1055e-02,\n",
      "          7.6899e-03, -4.5109e-03],\n",
      "        [-4.2128e-03, -1.8097e-02,  1.1364e-02,  ..., -1.9879e-02,\n",
      "          2.4911e-02,  2.7932e-03],\n",
      "        [-2.4500e-03,  2.7684e-03,  2.6685e-03,  ..., -6.4828e-03,\n",
      "         -2.4765e-04,  1.5845e-02]])), ('classifier.6.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])\n"
     ]
    }
   ],
   "source": [
    "def eg_3_4_0():\n",
    "  \"\"\"\n",
    "  Eg3.4.0 : model.state_dict()\n",
    "  \"\"\"\n",
    "  from torchvision import models\n",
    "\n",
    "  model_vgg16 = models.vgg16()\n",
    "  print(\"model_vgg16.state_dict(): {}\".format(model_vgg16.state_dict()))\n",
    "\n",
    "eg_3_4_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eg_3_4_1():\n",
    "  \"\"\"\n",
    "  Eg3.4.1 : torch.save(model.state_dict(), f)\n",
    "  \"\"\"\n",
    "  from torchvision import models\n",
    "\n",
    "  model_vgg16 = models.vgg16()\n",
    "  torch.save(model_vgg16.state_dict(), \"./vgg16.pth\",)\n",
    "\n",
    "eg_3_4_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_keys: []\n",
      "unexpected_keys: []\n"
     ]
    }
   ],
   "source": [
    "def eg_3_4_2():\n",
    "  \"\"\"\n",
    "  Eg3.4.2 : model.load_state_dict()\n",
    "  \"\"\"\n",
    "  from torchvision import models\n",
    "\n",
    "  model_vgg16 = models.vgg16()\n",
    "  state_dict = torch.load(\"./vgg16.pth\", map_location=\"cpu\")\n",
    "  missing_keys, unexpected_keys = model_vgg16.load_state_dict(state_dict, strict=True)\n",
    "  print(\"missing_keys: {}\".format(missing_keys))\n",
    "  print(\"unexpected_keys: {}\".format(unexpected_keys))\n",
    "\n",
    "eg_3_4_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_keys: ['features.0.bias', 'features.2.bias', 'features.5.bias', 'features.7.bias', 'features.10.bias', 'features.12.bias', 'features.14.bias', 'features.17.bias', 'features.19.bias', 'features.21.bias', 'features.24.bias', 'features.26.bias', 'features.28.bias', 'classifier.0.bias', 'classifier.3.bias', 'classifier.6.bias']\n",
      "unexpected_keys: []\n"
     ]
    }
   ],
   "source": [
    "def eg_3_4_3():\n",
    "  \"\"\"\n",
    "  Eg3.4.3 : strict=False\n",
    "  \"\"\"\n",
    "  from torchvision import models\n",
    "\n",
    "  model_vgg16 = models.vgg16()\n",
    "  state_dict = torch.load(\"./vgg16.pth\", map_location=\"cpu\")\n",
    "  for key in list(state_dict.keys()):\n",
    "    if \".bias\" in key:\n",
    "      del state_dict[key]\n",
    "\n",
    "  missing_keys, unexpected_keys = model_vgg16.load_state_dict(state_dict, strict=False)\n",
    "  print(\"missing_keys: {}\".format(missing_keys))\n",
    "  print(\"unexpected_keys: {}\".format(unexpected_keys))\n",
    "\n",
    "eg_3_4_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 利用 `torch.utils.model_zoo.load_url()` 下载预训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eg_3_5():\n",
    "  \"\"\"\n",
    "  Eg3.5 : torch.utils.model_zoo.load_url()\n",
    "  \"\"\"\n",
    "  from torch.utils import model_zoo\n",
    "  from torchvision import models\n",
    "\n",
    "  model_alexnet = models.alexnet()\n",
    "  state_dict = model_zoo.load_url('http://download.pytorch.org/models/alexnet-owt-7be5be79.pth')\n",
    "  model_alexnet.load_state_dict(state_dict)\n",
    "\n",
    "eg_3_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 调用 `torch.optim` 模块中的优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "transform = transforms.Compose(\n",
    "  [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "  ]\n",
    ")\n",
    "\n",
    "train_dataset = MNIST(root=\"./mnist_data\",\n",
    "                      train=True,\n",
    "                      transform=transform,\n",
    "                      target_transform=None,\n",
    "                      download=False)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=10000,\n",
    "                          shuffle=True)\n",
    "class SimpleModel(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(SimpleModel, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=(1, 1))\n",
    "      self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(1, 1))\n",
    "      self.relu = nn.ReLU(inplace=True)\n",
    "      self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "      self.linear = nn.Linear(in_features=5*28*28, out_features=10, bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.conv1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.conv2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.linear(x)\n",
    "      x = self.relu(x)\n",
    "      return x\n",
    "\n",
    "model = SimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optim.state_dict(): {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4]}]}\n"
     ]
    }
   ],
   "source": [
    "def eg_4_0():\n",
    "  \"\"\"\n",
    "  Eg4.0 : torch.optim\n",
    "  \"\"\"\n",
    "  from torch import optim\n",
    "  optimizer = optim.SGD(params=model.parameters(), lr=0.0001, momentum=0.9)\n",
    "  print(\"optim.state_dict(): {}\".format(optimizer.state_dict()))\n",
    "\n",
    "eg_4_0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 注意 `params`参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optim.state_dict(): {'state': {}, 'param_groups': [{'lr': 0.0001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "def eg_4_1():\n",
    "  \"\"\"\n",
    "  Eg4.1 : params\n",
    "  \"\"\"\n",
    "  from torch import optim\n",
    "  params = [param for name, param in model.named_parameters() if \".bias\" in name]\n",
    "  optimizer = optim.SGD(params=params, lr=0.0001, momentum=0.9)\n",
    "  print(\"optim.state_dict(): {}\".format(optimizer.state_dict()))\n",
    "\n",
    "eg_4_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 通过 `optimizer.zero_grad()` `loss.backward()` `optimizer.step()` 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 0: 100%|██████████| 6/6 [00:29<00:00,  4.87s/it]\n",
      "EPOCH: 1:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0,  loss: 2.300301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 1: 100%|██████████| 6/6 [00:30<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1,  loss: 2.300429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def eg_4_2():\n",
    "  \"\"\"\n",
    "  Eg4.2 : zero_grad(), step()\n",
    "  \"\"\"\n",
    "  from torch import optim\n",
    "  from tqdm import tqdm\n",
    "  optimizer = optim.SGD(params=model.parameters(), lr=0.001, momentum=0.9)\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  for epoch in range(2):\n",
    "    with tqdm(train_loader, desc=\"EPOCH: {}\".format(epoch)) as train_bar:\n",
    "      for (x, y) in train_bar:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch: {},  loss: {:.6f}\".format(epoch, loss))\n",
    "\n",
    "eg_4_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] 综上所述，完成训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] 美化代码，下次一定！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
